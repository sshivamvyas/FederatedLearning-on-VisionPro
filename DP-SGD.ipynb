{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3786591,"sourceType":"datasetVersion","datasetId":2259046}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"quadeer15sh/lfw-facial-recognition\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T15:59:11.923014Z","iopub.execute_input":"2025-12-24T15:59:11.923464Z","iopub.status.idle":"2025-12-24T16:00:35.579871Z","shell.execute_reply.started":"2025-12-24T15:59:11.923427Z","shell.execute_reply":"2025-12-24T16:00:35.578766Z"}},"outputs":[{"name":"stdout","text":"Mounting files to /kaggle/input/lfw-facial-recognition...\nPath to dataset files: /kaggle/input/lfw-facial-recognition\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# FL with No Protection (Fed Avg) with 50 Client","metadata":{}},{"cell_type":"code","source":"# Single-cell runnable script: FedAvg (no protection) with LeNet on a local face dataset\n# and IDLG-style reconstruction attack during training using L-BFGS.\n#\n# This version includes fixes for:\n# - Ensuring captured label/image are single-example (shape (1,) and (1,C,H,W))\n# - Defensive shape checks to avoid batch-size mismatches during reconstruction\n# - Robust handling of unexpected batch shapes from DataLoader\n#\n# Requirements: torch, torchvision, numpy, pillow, scikit-image, tqdm, sklearn\n\nimport os\nimport random\nimport math\nimport json\nfrom collections import defaultdict\nfrom pathlib import Path\nfrom tqdm import tqdm\n\nimport numpy as np\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as T\nfrom skimage.metrics import structural_similarity as ssim\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# -----------------------------\n# Experiment hyperparameters\n# -----------------------------\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nSEED = 42\n\n# Federated learning variables\nNUM_CLIENTS = 50                 # total clients\nCLIENTS_PER_ROUND = 10           # sampled clients per round\nROUNDS = 100                     # total federated rounds\nLOCAL_EPOCHS = 1                 # local epochs per client (E)\nLOCAL_BATCH_SIZE = 1             # batch size on client (B) -> 1 for strong leakage\nCLIENT_LR = 0.01                 # client optimizer lr\nMOMENTUM = 0.9\n\n# Model / data variables\nIMAGE_SIZE = 64                  # resize images to 64x64\nINPUT_CHANNELS = 3\nNUM_CLASSES = None               # set after dataset scan\n\n# Attack variables (IDLG with L-BFGS)\nATTACK_USE_LBFGS = True\nATTACK_LBFGS_MAX_ITER = 300\nATTACK_LBFGS_LINESEARCH = True\nATTACK_INIT = \"random\"           # \"random\" or \"mean_face\"\nATTACK_TV_WEIGHT = 1e-4\nATTACK_GRAD_MATCH_WEIGHT = 1.0\nATTACK_COSINE_THRESHOLD = 0.8    # threshold for attack success (cosine similarity)\nATTACK_EVERY_N_ROUNDS = 5        # attack frequency\n\n# Reconstruction image shape\nRECON_SHAPE = (1, INPUT_CHANNELS, IMAGE_SIZE, IMAGE_SIZE)\n\n# Logging / misc\nPRINT_EVERY = 5\nSAVE_RECON_DIR = \"./reconstructions\"\nos.makedirs(SAVE_RECON_DIR, exist_ok=True)\n\n# Determinism\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\nrandom.seed(SEED)\n\n# -----------------------------\n# Dataset utilities\n# -----------------------------\n# Set your dataset path here (example: Kaggle path provided earlier)\nDATA_ROOT = \"/kaggle/input/lfw-facial-recognition/Face Recognition\"\n# Choose which subfolders to include\nFOLDERS = [\"Faces\"]  # or [\"detected faces\", \"Faces\"]\n\n# Image transforms (normalize to [-1,1] as used in reconstruction)\ntransform = T.Compose([\n    T.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    T.ToTensor(),                       # [0,1]\n    T.Normalize(mean=[0.5]*3, std=[0.5]*3)  # -> [-1,1]\n])\n\n# Helper: gather all image file paths from the chosen folders\ndef gather_image_paths(root, folders):\n    paths = []\n    for f in folders:\n        folder = os.path.join(root, f)\n        if not os.path.isdir(folder):\n            continue\n        for fname in sorted(os.listdir(folder)):\n            if fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n                paths.append(os.path.join(folder, fname))\n    return sorted(paths)\n\nall_image_paths = gather_image_paths(DATA_ROOT, FOLDERS)\nif len(all_image_paths) == 0:\n    raise RuntimeError(f\"No images found in {FOLDERS} under {DATA_ROOT}. Check paths.\")\n\n# Identity extraction: everything before the last underscore (AJ_Cook_0001 -> AJ_Cook)\ndef identity_from_filename(path):\n    name = os.path.basename(path)\n    base = os.path.splitext(name)[0]\n    parts = base.split(\"_\")\n    if len(parts) >= 2:\n        return \"_\".join(parts[:-1])\n    return base\n\n# Build mapping identity -> list of image paths\nid_to_paths = defaultdict(list)\nfor p in all_image_paths:\n    id_ = identity_from_filename(p)\n    id_to_paths[id_].append(p)\n\n# Filter identities with at least 2 images (so we can have train/test per identity)\nvalid_id_to_paths = {k: v for k, v in id_to_paths.items() if len(v) >= 2}\nif len(valid_id_to_paths) == 0:\n    raise RuntimeError(\"No identities with >=2 images found. Check filename format or dataset.\")\n\n# Build a flat dataset list and label mapping\nall_valid_paths = []\nall_valid_labels = []\nunique_ids = sorted(valid_id_to_paths.keys())\nlabel_map = {id_: idx for idx, id_ in enumerate(unique_ids)}\nfor id_, paths in valid_id_to_paths.items():\n    for p in paths:\n        all_valid_paths.append(p)\n        all_valid_labels.append(label_map[id_])\n\nNUM_CLASSES = len(unique_ids)\nprint(f\"Found {len(all_valid_paths)} images across {NUM_CLASSES} identities (>=2 images each).\")\n\n# -----------------------------\n# PyTorch Dataset and client partitioning\n# -----------------------------\nclass FaceImageDataset(Dataset):\n    def __init__(self, paths, labels, transform=None):\n        self.paths = paths\n        self.labels = labels\n        self.transform = transform\n    def __len__(self):\n        return len(self.paths)\n    def __getitem__(self, idx):\n        p = self.paths[idx]\n        img = Image.open(p).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)  # should be (C,H,W)\n        label = self.labels[idx]\n        return img, label, p  # return path for debugging\n\n# Create a dataset object for convenience (we will create per-client subsets)\nfull_dataset = FaceImageDataset(all_valid_paths, all_valid_labels, transform=transform)\n\n# Partition identities across clients (non-IID: each client gets images of a few identities)\nclient_id_to_indices = {c: [] for c in range(NUM_CLIENTS)}\nidentities = list(unique_ids)\nrandom.shuffle(identities)\n# Round-robin assign identities to clients\nfor i, id_ in enumerate(identities):\n    client_id = i % NUM_CLIENTS\n    for p in valid_id_to_paths[id_]:\n        idx = all_valid_paths.index(p)\n        client_id_to_indices[client_id].append(idx)\n\nnum_nonempty = sum(1 for c in client_id_to_indices if len(client_id_to_indices[c]) > 0)\nprint(f\"Assigned identities to {num_nonempty} non-empty clients out of {NUM_CLIENTS} total clients.\")\n\n# Build client dataloaders\nclient_loaders = {}\nfor c in range(NUM_CLIENTS):\n    inds = client_id_to_indices[c]\n    if len(inds) == 0:\n        client_loaders[c] = None\n        continue\n    sub_paths = [all_valid_paths[i] for i in inds]\n    sub_labels = [all_valid_labels[i] for i in inds]\n    ds = FaceImageDataset(sub_paths, sub_labels, transform=transform)\n    loader = DataLoader(ds, batch_size=LOCAL_BATCH_SIZE, shuffle=True)\n    client_loaders[c] = loader\n\n# Build a small held-out test loader from each identity (take one image per identity)\ntest_paths = []\ntest_labels = []\nfor id_, paths in valid_id_to_paths.items():\n    p = paths[-1]\n    test_paths.append(p)\n    test_labels.append(label_map[id_])\ntest_ds = FaceImageDataset(test_paths, test_labels, transform=transform)\ntest_loader = DataLoader(test_ds, batch_size=32, shuffle=False)\n\n# -----------------------------\n# Model: small LeNet-like CNN\n# -----------------------------\nclass LeNetSmall(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        self.conv1 = nn.Conv2d(INPUT_CHANNELS, 6, kernel_size=5)\n        self.pool = nn.AvgPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n        with torch.no_grad():\n            dummy = torch.zeros(1, INPUT_CHANNELS, IMAGE_SIZE, IMAGE_SIZE)\n            x = self.pool(F.relu(self.conv1(dummy)))\n            x = self.pool(F.relu(self.conv2(x)))\n            flat = x.view(1, -1).shape[1]\n        self.fc1 = nn.Linear(flat, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, num_classes)\n\n    def forward(self, x, return_features=False):\n        x = F.relu(self.conv1(x))\n        x = self.pool(x)\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        x = x.view(x.size(0), -1)\n        feat = F.relu(self.fc1(x))\n        feat = F.relu(self.fc2(feat))\n        logits = self.fc3(feat)\n        if return_features:\n            return feat, logits\n        return logits\n\n# Instantiate global model\nglobal_model = LeNetSmall(NUM_CLASSES).to(DEVICE)\nglobal_state = {k: v.cpu() for k, v in global_model.state_dict().items()}\n\n# Helper to create model from state dict\ndef model_from_state(state_dict):\n    m = LeNetSmall(NUM_CLASSES).to(DEVICE)\n    sd = {k: v.to(DEVICE) for k, v in state_dict.items()}\n    m.load_state_dict(sd)\n    return m\n\n# -----------------------------\n# Utility: ensure image tensors have shape (B,C,H,W)\n# -----------------------------\ndef ensure_batch_image_shape(x):\n    # x may be (C,H,W), (1,C,H,W), (B,C,H,W), or (B,1,C,H,W) etc.\n    # Return a tensor with shape (B,C,H,W)\n    if isinstance(x, torch.Tensor):\n        if x.dim() == 3:\n            return x.unsqueeze(0)\n        if x.dim() == 5 and x.size(1) == 1:\n            # shape (B,1,C,H,W) -> squeeze dim1\n            return x.squeeze(1)\n        if x.dim() == 5 and x.size(2) == 1:\n            # shape (B,C,1,H,W) unlikely, try to reshape\n            return x.squeeze(2)\n        return x\n    else:\n        return x\n\n# -----------------------------\n# FedAvg client update (single-step) with gradient capture\n# -----------------------------\ndef get_model_copy_for_client(state_dict):\n    return model_from_state(state_dict)\n\ndef client_update(client_id, global_state, return_grad_snapshot=False):\n    loader = client_loaders[client_id]\n    if loader is None:\n        return None, None, None, None\n    local_model = get_model_copy_for_client(global_state)\n    opt = torch.optim.SGD(local_model.parameters(), lr=CLIENT_LR, momentum=MOMENTUM)\n    local_model.train()\n    grad_snapshot = None\n    captured_label = None\n    captured_image = None\n    for epoch in range(LOCAL_EPOCHS):\n        for x, y, pth in loader:\n            # x: (B,C,H,W) normally; guard against extra dims\n            x = ensure_batch_image_shape(x)\n            # Defensive: if DataLoader produced shape (B,1,C,H,W) or similar, squeeze\n            if x.dim() == 5 and x.size(1) == 1:\n                x = x.squeeze(1)\n            x = x.to(DEVICE)\n            y = torch.tensor(y) if not isinstance(y, torch.Tensor) else y\n            y = y.to(DEVICE)\n            opt.zero_grad()\n            logits = local_model(x)\n            loss = F.cross_entropy(logits, y)\n            loss.backward()\n            # Capture per-parameter gradients BEFORE optimizer.step (this is what attacker sees)\n            if return_grad_snapshot and grad_snapshot is None:\n                # capture per-parameter gradients (CPU)\n                grad_snapshot = [p.grad.detach().cpu().clone() if p.grad is not None else None for p in local_model.parameters()]\n\n                # Ensure we capture a single example (first in the batch)\n                # y may be shape (B,) or (B,1); take first element and keep batch dim (1,)\n                if y.dim() == 0:\n                    captured_label = y.detach().cpu().clone().unsqueeze(0)   # scalar -> (1,)\n                else:\n                    captured_label = y.detach().cpu().clone().view(-1)[0:1]  # (1,)\n\n                # captured_image: ensure shape (1,C,H,W)\n                captured_image = x.detach().cpu().clone()[0:1]               # keep first example only\n\n                # Debug print (optional)\n                # print(f\"[DEBUG] client {client_id} captured shapes: x {x.shape}, y {y.shape}\")\n\n            opt.step()\n            # For strong leakage baseline, break after first batch\n            if LOCAL_EPOCHS == 1:\n                break\n    # compute delta = local_params - global_params (on CPU)\n    new_state = {k: v.cpu() for k, v in local_model.state_dict().items()}\n    delta = {k: new_state[k] - global_state[k] for k in new_state.keys()}\n    return delta, grad_snapshot, captured_label, captured_image\n\n# -----------------------------\n# Server aggregation (FedAvg)\n# -----------------------------\ndef server_aggregate(global_state, client_deltas, client_sizes):\n    total = sum(client_sizes) if sum(client_sizes) > 0 else 1\n    agg = {k: torch.zeros_like(v) for k, v in global_state.items()}\n    for delta, size in zip(client_deltas, client_sizes):\n        if delta is None:\n            continue\n        weight = size / total\n        for k in agg.keys():\n            agg[k] += delta[k] * weight\n    new_state = {k: global_state[k] + agg[k] for k in global_state.keys()}\n    return new_state\n\n# -----------------------------\n# Reconstruction utilities (IDLG with L-BFGS)\n# -----------------------------\ndef flatten_grads(grad_list):\n    vecs = []\n    for g in grad_list:\n        if g is None:\n            continue\n        # ensure on DEVICE\n        if not g.is_cuda:\n            g = g.to(DEVICE)\n        vecs.append(g.view(-1))\n    if len(vecs) == 0:\n        return torch.tensor([], device=DEVICE)\n    return torch.cat(vecs)\n\ndef tv_loss(img):\n    return torch.mean(torch.abs(img[:, :, :, 1:] - img[:, :, :, :-1])) + \\\n           torch.mean(torch.abs(img[:, :, 1:, :] - img[:, :, :-1, :]))\n\ndef assert_shapes_for_recon(x_init, observed_label, observed_grads):\n    # x_init should be (1,C,H,W)\n    if not isinstance(x_init, torch.Tensor):\n        raise RuntimeError(\"x_init must be a torch.Tensor\")\n    if x_init.dim() != 4 or x_init.size(0) != 1:\n        raise RuntimeError(f\"Reconstruction input must be (1,C,H,W), got {x_init.shape}\")\n    # observed_label should be (1,)\n    if observed_label is None:\n        raise RuntimeError(\"Observed label is None\")\n    if observed_label.dim() != 1 or observed_label.size(0) != 1:\n        raise RuntimeError(f\"Observed label must be shape (1,), got {observed_label.shape}\")\n    # grads: ensure flattened length > 0\n    flat = flatten_grads(observed_grads)\n    if flat.numel() == 0:\n        raise RuntimeError(\"Observed grads flattened to zero length; check grad capture\")\n\ndef reconstruct_idlg_lbfgs(model_state_for_attack, observed_grads_cpu, observed_label_cpu, iters=ATTACK_LBFGS_MAX_ITER):\n    # Ensure observed_label_cpu is shape (1,)\n    if observed_label_cpu is None:\n        raise ValueError(\"No observed label provided for reconstruction\")\n    if observed_label_cpu.dim() == 0:\n        observed_label_cpu = observed_label_cpu.unsqueeze(0)\n    else:\n        observed_label_cpu = observed_label_cpu.view(-1)[0:1]\n\n    # Build a model instance loaded with the pre-update state (on DEVICE)\n    model = model_from_state(model_state_for_attack)\n    model.eval()\n\n    # Move observed grads to DEVICE and flatten\n    obs = [g.to(DEVICE) if g is not None else None for g in observed_grads_cpu]\n    obs_flat = flatten_grads(obs).detach()\n\n    # Initialize x_hat in the same normalized space as training ([-1,1])\n    if ATTACK_INIT == \"random\":\n        x_hat = torch.randn(RECON_SHAPE, device=DEVICE, requires_grad=True)\n    else:\n        x_hat = torch.randn(RECON_SHAPE, device=DEVICE, requires_grad=True)\n\n    # Defensive shape assertion\n    try:\n        assert_shapes_for_recon(x_hat, observed_label_cpu, observed_grads_cpu)\n    except Exception as e:\n        raise RuntimeError(f\"Pre-reconstruction shape check failed: {e}\")\n\n    # Use LBFGS optimizer\n    optimizer = torch.optim.LBFGS([x_hat], max_iter=iters, line_search_fn='strong_wolfe' if ATTACK_LBFGS_LINESEARCH else None)\n\n    def closure():\n        optimizer.zero_grad()\n        x_in = ensure_batch_image_shape(x_hat)\n        logits = model(x_in)\n        loss_cls = F.cross_entropy(logits, observed_label_cpu.to(DEVICE))\n        grads_hat = torch.autograd.grad(loss_cls, list(model.parameters()), create_graph=True)\n        grads_hat_flat = flatten_grads(grads_hat)\n        if obs_flat.numel() == 0 or grads_hat_flat.numel() == 0:\n            loss = torch.tensor(0.0, device=DEVICE, requires_grad=True)\n            loss.backward()\n            return loss\n        loss_match = F.mse_loss(grads_hat_flat, obs_flat)\n        loss = ATTACK_GRAD_MATCH_WEIGHT * loss_match + ATTACK_TV_WEIGHT * tv_loss(x_hat)\n        loss.backward()\n        return loss\n\n    try:\n        optimizer.step(closure)\n    except Exception as e:\n        # LBFGS sometimes raises on line search; fallback to Adam for a while\n        print(\"LBFGS failed, falling back to Adam:\", e)\n        opt_adam = torch.optim.Adam([x_hat], lr=0.05)\n        for _ in range(500):\n            opt_adam.zero_grad()\n            x_in = ensure_batch_image_shape(x_hat)\n            logits = model(x_in)\n            loss_cls = F.cross_entropy(logits, observed_label_cpu.to(DEVICE))\n            grads_hat = torch.autograd.grad(loss_cls, list(model.parameters()), create_graph=True)\n            grads_hat_flat = flatten_grads(grads_hat)\n            loss_match = F.mse_loss(grads_hat_flat, obs_flat)\n            loss = ATTACK_GRAD_MATCH_WEIGHT * loss_match + ATTACK_TV_WEIGHT * tv_loss(x_hat)\n            loss.backward()\n            opt_adam.step()\n            with torch.no_grad():\n                x_hat.clamp_(-1, 1)\n\n    with torch.no_grad():\n        x_rec = x_hat.clamp_(-1, 1).detach().cpu()\n    return x_rec\n\n# -----------------------------\n# Evaluation metrics\n# -----------------------------\ndef denorm(img_tensor):\n    img = img_tensor.clone()\n    img = (img * 0.5) + 0.5\n    return img.clamp(0,1)\n\ndef compute_ssim(img1, img2):\n    a = img1.squeeze(0).permute(1,2,0).numpy()\n    b = img2.squeeze(0).permute(1,2,0).numpy()\n    s = 0.0\n    for ch in range(a.shape[2]):\n        s += ssim(a[:,:,ch], b[:,:,ch], data_range=1.0)\n    return s / a.shape[2]\n\ndef compute_cosine_similarity_feature(model_state, img1, img2):\n    model = model_from_state(model_state)\n    model.eval()\n    with torch.no_grad():\n        f1, _ = model(ensure_batch_image_shape(img1).to(DEVICE), return_features=True)\n        f2, _ = model(ensure_batch_image_shape(img2).to(DEVICE), return_features=True)\n    f1 = f1.cpu().numpy()\n    f2 = f2.cpu().numpy()\n    return float(cosine_similarity(f1, f2)[0,0])\n\ndef evaluate_accuracy(model_state, dataloader):\n    model = model_from_state(model_state)\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for x, y, _ in dataloader:\n            x = ensure_batch_image_shape(x).to(DEVICE)\n            y = y.to(DEVICE)\n            logits = model(x)\n            preds = logits.argmax(dim=1)\n            correct += (preds == y).sum().item()\n            total += y.size(0)\n    return correct / total if total > 0 else 0.0\n\n# -----------------------------\n# Training loop with attack during training\n# -----------------------------\nattack_logs = []\nglobal_state = {k: v.cpu() for k, v in global_model.state_dict().items()}\n\nfor rnd in range(ROUNDS):\n    available_clients = [c for c in range(NUM_CLIENTS) if client_loaders[c] is not None]\n    sampled = random.sample(available_clients, min(CLIENTS_PER_ROUND, len(available_clients)))\n    client_deltas = []\n    client_sizes = []\n\n    victim_client = sampled[0] if len(sampled) > 0 else None\n    captured_grad = None\n    captured_label = None\n    captured_image = None\n    model_state_sent_to_client = None\n\n    for c in sampled:\n        model_state_sent_to_client = {k: v.clone() for k, v in global_state.items()}\n        if c == victim_client:\n            delta, grad_snapshot, cap_label, cap_image = client_update(c, model_state_sent_to_client, return_grad_snapshot=True)\n            captured_grad = grad_snapshot\n            captured_label = cap_label\n            captured_image = cap_image\n        else:\n            delta, _, _, _ = client_update(c, model_state_sent_to_client, return_grad_snapshot=False)\n        client_deltas.append(delta)\n        size = len(client_loaders[c].dataset) if client_loaders[c] is not None else 0\n        client_sizes.append(size)\n\n    global_state = server_aggregate(global_state, client_deltas, client_sizes)\n\n    if rnd % PRINT_EVERY == 0 or rnd == ROUNDS - 1:\n        acc = evaluate_accuracy(global_state, test_loader)\n        print(f\"Round {rnd:03d}/{ROUNDS:03d} - Test accuracy: {acc:.4f} - sampled {len(sampled)} clients\")\n\n    if (rnd % ATTACK_EVERY_N_ROUNDS == 0) and (captured_grad is not None):\n        # Ensure captured_label and captured_image are present and shaped correctly\n        try:\n            if captured_label is None or captured_image is None:\n                raise RuntimeError(\"Captured label/image missing for attack\")\n            # Force shapes: label (1,), image (1,C,H,W)\n            if captured_label.dim() == 0:\n                captured_label = captured_label.unsqueeze(0)\n            else:\n                captured_label = captured_label.view(-1)[0:1]\n            if captured_image.dim() == 3:\n                captured_image = captured_image.unsqueeze(0)\n            elif captured_image.dim() == 5 and captured_image.size(1) == 1:\n                captured_image = captured_image.squeeze(1)\n            captured_image = captured_image[0:1]  # ensure single example\n        except Exception as e:\n            print(\"Captured data shape error, skipping attack this round:\", e)\n            continue\n\n        try:\n            reconstructed = reconstruct_idlg_lbfgs(model_state_sent_to_client, captured_grad, captured_label, iters=ATTACK_LBFGS_MAX_ITER)\n        except Exception as e:\n            print(\"Reconstruction failed:\", e)\n            reconstructed = None\n\n        if reconstructed is not None:\n            rec_den = denorm(reconstructed)\n            true_den = denorm(captured_image.cpu())\n\n            ssim_val = compute_ssim(rec_den, true_den)\n            cos_val = compute_cosine_similarity_feature(model_state_sent_to_client, rec_den.unsqueeze(0), true_den.unsqueeze(0))\n            success = float(cos_val >= ATTACK_COSINE_THRESHOLD)\n\n            def tensor_to_pil(img_tensor, fname):\n                arr = (img_tensor.squeeze(0).permute(1,2,0).numpy() * 255).astype(np.uint8)\n                Image.fromarray(arr).save(fname)\n\n            fname_rec = os.path.join(SAVE_RECON_DIR, f\"round{rnd:03d}_client{victim_client}_rec.png\")\n            fname_true = os.path.join(SAVE_RECON_DIR, f\"round{rnd:03d}_client{victim_client}_true.png\")\n            try:\n                tensor_to_pil(rec_den, fname_rec)\n                tensor_to_pil(true_den, fname_true)\n            except Exception:\n                np.save(fname_rec + \".npy\", rec_den.numpy())\n                np.save(fname_true + \".npy\", true_den.numpy())\n\n            log_entry = {\n                \"round\": int(rnd),\n                \"victim_client\": int(victim_client),\n                \"ssim\": float(ssim_val),\n                \"cosine\": float(cos_val),\n                \"success\": float(success),\n                \"recon_path\": fname_rec,\n                \"true_path\": fname_true,\n                \"label\": int(captured_label.item())\n            }\n            attack_logs.append(log_entry)\n            print(f\"[Attack] Round {rnd} client {victim_client}: SSIM={ssim_val:.4f}, Cos={cos_val:.4f}, Success={success}\")\n\n# -----------------------------\n# Final aggregated attack metrics and save logs\n# -----------------------------\ntotal_attacks = len(attack_logs)\nif total_attacks > 0:\n    avg_ssim = sum([e[\"ssim\"] for e in attack_logs]) / total_attacks\n    avg_cos = sum([e[\"cosine\"] for e in attack_logs]) / total_attacks\n    success_rate = sum([e[\"success\"] for e in attack_logs]) / total_attacks\nelse:\n    avg_ssim = avg_cos = success_rate = 0.0\n\nprint(\"=== Attack summary ===\")\nprint(f\"Attacks run: {total_attacks}\")\nprint(f\"Avg SSIM: {avg_ssim:.4f}\")\nprint(f\"Avg Cosine: {avg_cos:.4f}\")\nprint(f\"Success rate (cos>={ATTACK_COSINE_THRESHOLD}): {success_rate:.3f}\")\n\nwith open(os.path.join(SAVE_RECON_DIR, \"attack_logs.json\"), \"w\") as f:\n    json.dump(attack_logs, f, indent=2)\n\nprint(\"Reconstruction images and logs saved to:\", SAVE_RECON_DIR)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T19:02:51.976713Z","iopub.execute_input":"2025-12-24T19:02:51.977470Z","iopub.status.idle":"2025-12-24T19:04:32.498135Z","shell.execute_reply.started":"2025-12-24T19:02:51.977439Z","shell.execute_reply":"2025-12-24T19:04:32.497389Z"}},"outputs":[{"name":"stdout","text":"Found 9164 images across 1680 identities (>=2 images each).\nAssigned identities to 50 non-empty clients out of 50 total clients.\nRound 000/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 0 client 46: SSIM=0.0032, Cos=0.9888, Success=1.0\n[Attack] Round 1 client 9: SSIM=0.0098, Cos=0.9913, Success=1.0\n[Attack] Round 2 client 28: SSIM=0.0048, Cos=0.9900, Success=1.0\n[Attack] Round 3 client 28: SSIM=0.0028, Cos=0.9952, Success=1.0\n[Attack] Round 4 client 32: SSIM=0.0089, Cos=0.9968, Success=1.0\nRound 005/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 5 client 41: SSIM=0.0122, Cos=0.9879, Success=1.0\n[Attack] Round 6 client 28: SSIM=0.0005, Cos=0.9910, Success=1.0\n[Attack] Round 7 client 28: SSIM=0.0033, Cos=0.9856, Success=1.0\n[Attack] Round 8 client 45: SSIM=0.0038, Cos=0.9920, Success=1.0\n[Attack] Round 9 client 24: SSIM=0.0126, Cos=0.9878, Success=1.0\nRound 010/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 10 client 21: SSIM=0.0030, Cos=0.9918, Success=1.0\n[Attack] Round 11 client 21: SSIM=0.0058, Cos=0.9927, Success=1.0\n[Attack] Round 12 client 38: SSIM=0.0023, Cos=0.9913, Success=1.0\n[Attack] Round 13 client 5: SSIM=0.0040, Cos=0.9849, Success=1.0\n[Attack] Round 14 client 13: SSIM=0.0091, Cos=0.9927, Success=1.0\nRound 015/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 15 client 32: SSIM=0.0008, Cos=0.9861, Success=1.0\n[Attack] Round 16 client 24: SSIM=0.0065, Cos=0.9884, Success=1.0\n[Attack] Round 17 client 23: SSIM=0.0049, Cos=0.9838, Success=1.0\n[Attack] Round 18 client 15: SSIM=0.0019, Cos=0.9905, Success=1.0\n[Attack] Round 19 client 49: SSIM=0.0030, Cos=0.9872, Success=1.0\nRound 020/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 20 client 3: SSIM=0.0048, Cos=0.9769, Success=1.0\n[Attack] Round 21 client 48: SSIM=0.0070, Cos=0.9913, Success=1.0\n[Attack] Round 22 client 22: SSIM=-0.0030, Cos=0.9931, Success=1.0\n[Attack] Round 23 client 23: SSIM=-0.0006, Cos=0.9921, Success=1.0\n[Attack] Round 24 client 18: SSIM=0.0103, Cos=0.9972, Success=1.0\nRound 025/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 25 client 1: SSIM=0.0023, Cos=0.9865, Success=1.0\n[Attack] Round 26 client 15: SSIM=0.0094, Cos=0.9929, Success=1.0\n[Attack] Round 27 client 7: SSIM=0.0070, Cos=0.9850, Success=1.0\n[Attack] Round 28 client 18: SSIM=0.0060, Cos=0.9934, Success=1.0\n[Attack] Round 29 client 33: SSIM=0.0065, Cos=0.9964, Success=1.0\nRound 030/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 30 client 30: SSIM=-0.0016, Cos=0.9934, Success=1.0\n[Attack] Round 31 client 15: SSIM=0.0103, Cos=0.9903, Success=1.0\n[Attack] Round 32 client 34: SSIM=0.0068, Cos=0.9925, Success=1.0\n[Attack] Round 33 client 4: SSIM=0.0091, Cos=0.9938, Success=1.0\n[Attack] Round 34 client 19: SSIM=-0.0009, Cos=0.9921, Success=1.0\nRound 035/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 35 client 22: SSIM=0.0049, Cos=0.9944, Success=1.0\n[Attack] Round 36 client 24: SSIM=-0.0017, Cos=0.9897, Success=1.0\n[Attack] Round 37 client 46: SSIM=0.0023, Cos=0.9947, Success=1.0\n[Attack] Round 38 client 5: SSIM=0.0056, Cos=0.9863, Success=1.0\n[Attack] Round 39 client 22: SSIM=-0.0002, Cos=0.9919, Success=1.0\nRound 040/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 40 client 4: SSIM=0.0044, Cos=0.9862, Success=1.0\n[Attack] Round 41 client 38: SSIM=0.0128, Cos=0.9884, Success=1.0\n[Attack] Round 42 client 24: SSIM=0.0022, Cos=0.9881, Success=1.0\n[Attack] Round 43 client 48: SSIM=0.0018, Cos=0.9956, Success=1.0\n[Attack] Round 44 client 15: SSIM=0.0019, Cos=0.9901, Success=1.0\nRound 045/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 45 client 49: SSIM=-0.0027, Cos=0.9910, Success=1.0\n[Attack] Round 46 client 8: SSIM=0.0115, Cos=0.9947, Success=1.0\n[Attack] Round 47 client 35: SSIM=0.0010, Cos=0.9873, Success=1.0\n[Attack] Round 48 client 14: SSIM=0.0030, Cos=0.9924, Success=1.0\n[Attack] Round 49 client 23: SSIM=0.0086, Cos=0.9916, Success=1.0\nRound 050/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 50 client 33: SSIM=0.0034, Cos=0.9930, Success=1.0\n[Attack] Round 51 client 29: SSIM=0.0133, Cos=0.9888, Success=1.0\n[Attack] Round 52 client 27: SSIM=0.0035, Cos=0.9934, Success=1.0\n[Attack] Round 53 client 45: SSIM=-0.0008, Cos=0.9895, Success=1.0\n[Attack] Round 54 client 17: SSIM=0.0054, Cos=0.9937, Success=1.0\nRound 055/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 55 client 37: SSIM=0.0024, Cos=0.9961, Success=1.0\n[Attack] Round 56 client 1: SSIM=0.0036, Cos=0.9881, Success=1.0\n[Attack] Round 57 client 39: SSIM=0.0081, Cos=0.9866, Success=1.0\n[Attack] Round 58 client 15: SSIM=0.0105, Cos=0.9906, Success=1.0\n[Attack] Round 59 client 30: SSIM=0.0068, Cos=0.9936, Success=1.0\nRound 060/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 60 client 8: SSIM=0.0080, Cos=0.9913, Success=1.0\n[Attack] Round 61 client 17: SSIM=0.0134, Cos=0.9883, Success=1.0\n[Attack] Round 62 client 15: SSIM=0.0115, Cos=0.9931, Success=1.0\n[Attack] Round 63 client 31: SSIM=0.0042, Cos=0.9896, Success=1.0\n[Attack] Round 64 client 37: SSIM=0.0061, Cos=0.9850, Success=1.0\nRound 065/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 65 client 34: SSIM=-0.0004, Cos=0.9932, Success=1.0\n[Attack] Round 66 client 25: SSIM=0.0040, Cos=0.9899, Success=1.0\n[Attack] Round 67 client 32: SSIM=0.0061, Cos=0.9931, Success=1.0\n[Attack] Round 68 client 25: SSIM=0.0095, Cos=0.9906, Success=1.0\n[Attack] Round 69 client 32: SSIM=-0.0012, Cos=0.9911, Success=1.0\nRound 070/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 70 client 38: SSIM=0.0090, Cos=0.9922, Success=1.0\n[Attack] Round 71 client 37: SSIM=0.0062, Cos=0.9820, Success=1.0\n[Attack] Round 72 client 23: SSIM=0.0060, Cos=0.9962, Success=1.0\n[Attack] Round 73 client 30: SSIM=0.0085, Cos=0.9961, Success=1.0\n[Attack] Round 74 client 33: SSIM=0.0112, Cos=0.9926, Success=1.0\nRound 075/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 75 client 44: SSIM=0.0084, Cos=0.9932, Success=1.0\n[Attack] Round 76 client 26: SSIM=0.0092, Cos=0.9947, Success=1.0\n[Attack] Round 77 client 42: SSIM=0.0081, Cos=0.9943, Success=1.0\n[Attack] Round 78 client 22: SSIM=0.0060, Cos=0.9840, Success=1.0\n[Attack] Round 79 client 15: SSIM=-0.0096, Cos=0.9855, Success=1.0\nRound 080/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 80 client 30: SSIM=0.0056, Cos=0.9923, Success=1.0\n[Attack] Round 81 client 25: SSIM=0.0029, Cos=0.9924, Success=1.0\n[Attack] Round 82 client 47: SSIM=0.0075, Cos=0.9935, Success=1.0\n[Attack] Round 83 client 39: SSIM=0.0023, Cos=0.9910, Success=1.0\n[Attack] Round 84 client 14: SSIM=0.0034, Cos=0.9943, Success=1.0\nRound 085/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 85 client 10: SSIM=0.0043, Cos=0.9907, Success=1.0\n[Attack] Round 86 client 41: SSIM=0.0056, Cos=0.9935, Success=1.0\n[Attack] Round 87 client 11: SSIM=-0.0055, Cos=0.9911, Success=1.0\n[Attack] Round 88 client 38: SSIM=0.0070, Cos=0.9940, Success=1.0\n[Attack] Round 89 client 32: SSIM=0.0059, Cos=0.9891, Success=1.0\nRound 090/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 90 client 45: SSIM=-0.0004, Cos=0.9898, Success=1.0\n[Attack] Round 91 client 40: SSIM=0.0054, Cos=0.9919, Success=1.0\n[Attack] Round 92 client 8: SSIM=-0.0001, Cos=0.9894, Success=1.0\n[Attack] Round 93 client 21: SSIM=0.0019, Cos=0.9940, Success=1.0\n[Attack] Round 94 client 3: SSIM=0.0033, Cos=0.9854, Success=1.0\nRound 095/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 95 client 40: SSIM=0.0089, Cos=0.9934, Success=1.0\n[Attack] Round 96 client 47: SSIM=0.0090, Cos=0.9892, Success=1.0\n[Attack] Round 97 client 43: SSIM=0.0079, Cos=0.9941, Success=1.0\n[Attack] Round 98 client 7: SSIM=0.0036, Cos=0.9915, Success=1.0\nRound 099/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 99 client 33: SSIM=0.0059, Cos=0.9861, Success=1.0\n=== Attack summary ===\nAttacks run: 100\nAvg SSIM: 0.0050\nAvg Cosine: 0.9908\nSuccess rate (cos>=0.8): 1.000\nReconstruction images and logs saved to: ./reconstructions\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# FL with No Protection (Fed Avg) with 100 Client","metadata":{}},{"cell_type":"code","source":"# Single-cell runnable script: FedAvg (no protection) with LeNet on a local face dataset\n# and IDLG-style reconstruction attack during training using L-BFGS.\n#\n# This version includes fixes for:\n# - Ensuring captured label/image are single-example (shape (1,) and (1,C,H,W))\n# - Defensive shape checks to avoid batch-size mismatches during reconstruction\n# - Robust handling of unexpected batch shapes from DataLoader\n#\n# Requirements: torch, torchvision, numpy, pillow, scikit-image, tqdm, sklearn\n\nimport os\nimport random\nimport math\nimport json\nfrom collections import defaultdict\nfrom pathlib import Path\nfrom tqdm import tqdm\n\nimport numpy as np\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as T\nfrom skimage.metrics import structural_similarity as ssim\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# -----------------------------\n# Experiment hyperparameters\n# -----------------------------\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nSEED = 42\n\n# Federated learning variables\nNUM_CLIENTS = 100                 # total clients\nCLIENTS_PER_ROUND = 10           # sampled clients per round\nROUNDS = 100                     # total federated rounds\nLOCAL_EPOCHS = 1                 # local epochs per client (E)\nLOCAL_BATCH_SIZE = 1             # batch size on client (B) -> 1 for strong leakage\nCLIENT_LR = 0.01                 # client optimizer lr\nMOMENTUM = 0.9\n\n# Model / data variables\nIMAGE_SIZE = 64                  # resize images to 64x64\nINPUT_CHANNELS = 3\nNUM_CLASSES = None               # set after dataset scan\n\n# Attack variables (IDLG with L-BFGS)\nATTACK_USE_LBFGS = True\nATTACK_LBFGS_MAX_ITER = 300\nATTACK_LBFGS_LINESEARCH = True\nATTACK_INIT = \"random\"           # \"random\" or \"mean_face\"\nATTACK_TV_WEIGHT = 1e-4\nATTACK_GRAD_MATCH_WEIGHT = 1.0\nATTACK_COSINE_THRESHOLD = 0.8    # threshold for attack success (cosine similarity)\nATTACK_EVERY_N_ROUNDS = 5        # attack frequency\n\n# Reconstruction image shape\nRECON_SHAPE = (1, INPUT_CHANNELS, IMAGE_SIZE, IMAGE_SIZE)\n\n# Logging / misc\nPRINT_EVERY = 5\nSAVE_RECON_DIR = \"./reconstructions\"\nos.makedirs(SAVE_RECON_DIR, exist_ok=True)\n\n# Determinism\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\nrandom.seed(SEED)\n\n# -----------------------------\n# Dataset utilities\n# -----------------------------\n# Set your dataset path here (example: Kaggle path provided earlier)\nDATA_ROOT = \"/kaggle/input/lfw-facial-recognition/Face Recognition\"\n# Choose which subfolders to include\nFOLDERS = [\"Faces\"]  # or [\"detected faces\", \"Faces\"]\n\n# Image transforms (normalize to [-1,1] as used in reconstruction)\ntransform = T.Compose([\n    T.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    T.ToTensor(),                       # [0,1]\n    T.Normalize(mean=[0.5]*3, std=[0.5]*3)  # -> [-1,1]\n])\n\n# Helper: gather all image file paths from the chosen folders\ndef gather_image_paths(root, folders):\n    paths = []\n    for f in folders:\n        folder = os.path.join(root, f)\n        if not os.path.isdir(folder):\n            continue\n        for fname in sorted(os.listdir(folder)):\n            if fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n                paths.append(os.path.join(folder, fname))\n    return sorted(paths)\n\nall_image_paths = gather_image_paths(DATA_ROOT, FOLDERS)\nif len(all_image_paths) == 0:\n    raise RuntimeError(f\"No images found in {FOLDERS} under {DATA_ROOT}. Check paths.\")\n\n# Identity extraction: everything before the last underscore (AJ_Cook_0001 -> AJ_Cook)\ndef identity_from_filename(path):\n    name = os.path.basename(path)\n    base = os.path.splitext(name)[0]\n    parts = base.split(\"_\")\n    if len(parts) >= 2:\n        return \"_\".join(parts[:-1])\n    return base\n\n# Build mapping identity -> list of image paths\nid_to_paths = defaultdict(list)\nfor p in all_image_paths:\n    id_ = identity_from_filename(p)\n    id_to_paths[id_].append(p)\n\n# Filter identities with at least 2 images (so we can have train/test per identity)\nvalid_id_to_paths = {k: v for k, v in id_to_paths.items() if len(v) >= 2}\nif len(valid_id_to_paths) == 0:\n    raise RuntimeError(\"No identities with >=2 images found. Check filename format or dataset.\")\n\n# Build a flat dataset list and label mapping\nall_valid_paths = []\nall_valid_labels = []\nunique_ids = sorted(valid_id_to_paths.keys())\nlabel_map = {id_: idx for idx, id_ in enumerate(unique_ids)}\nfor id_, paths in valid_id_to_paths.items():\n    for p in paths:\n        all_valid_paths.append(p)\n        all_valid_labels.append(label_map[id_])\n\nNUM_CLASSES = len(unique_ids)\nprint(f\"Found {len(all_valid_paths)} images across {NUM_CLASSES} identities (>=2 images each).\")\n\n# -----------------------------\n# PyTorch Dataset and client partitioning\n# -----------------------------\nclass FaceImageDataset(Dataset):\n    def __init__(self, paths, labels, transform=None):\n        self.paths = paths\n        self.labels = labels\n        self.transform = transform\n    def __len__(self):\n        return len(self.paths)\n    def __getitem__(self, idx):\n        p = self.paths[idx]\n        img = Image.open(p).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)  # should be (C,H,W)\n        label = self.labels[idx]\n        return img, label, p  # return path for debugging\n\n# Create a dataset object for convenience (we will create per-client subsets)\nfull_dataset = FaceImageDataset(all_valid_paths, all_valid_labels, transform=transform)\n\n# Partition identities across clients (non-IID: each client gets images of a few identities)\nclient_id_to_indices = {c: [] for c in range(NUM_CLIENTS)}\nidentities = list(unique_ids)\nrandom.shuffle(identities)\n# Round-robin assign identities to clients\nfor i, id_ in enumerate(identities):\n    client_id = i % NUM_CLIENTS\n    for p in valid_id_to_paths[id_]:\n        idx = all_valid_paths.index(p)\n        client_id_to_indices[client_id].append(idx)\n\nnum_nonempty = sum(1 for c in client_id_to_indices if len(client_id_to_indices[c]) > 0)\nprint(f\"Assigned identities to {num_nonempty} non-empty clients out of {NUM_CLIENTS} total clients.\")\n\n# Build client dataloaders\nclient_loaders = {}\nfor c in range(NUM_CLIENTS):\n    inds = client_id_to_indices[c]\n    if len(inds) == 0:\n        client_loaders[c] = None\n        continue\n    sub_paths = [all_valid_paths[i] for i in inds]\n    sub_labels = [all_valid_labels[i] for i in inds]\n    ds = FaceImageDataset(sub_paths, sub_labels, transform=transform)\n    loader = DataLoader(ds, batch_size=LOCAL_BATCH_SIZE, shuffle=True)\n    client_loaders[c] = loader\n\n# Build a small held-out test loader from each identity (take one image per identity)\ntest_paths = []\ntest_labels = []\nfor id_, paths in valid_id_to_paths.items():\n    p = paths[-1]\n    test_paths.append(p)\n    test_labels.append(label_map[id_])\ntest_ds = FaceImageDataset(test_paths, test_labels, transform=transform)\ntest_loader = DataLoader(test_ds, batch_size=32, shuffle=False)\n\n# -----------------------------\n# Model: small LeNet-like CNN\n# -----------------------------\nclass LeNetSmall(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        self.conv1 = nn.Conv2d(INPUT_CHANNELS, 6, kernel_size=5)\n        self.pool = nn.AvgPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n        with torch.no_grad():\n            dummy = torch.zeros(1, INPUT_CHANNELS, IMAGE_SIZE, IMAGE_SIZE)\n            x = self.pool(F.relu(self.conv1(dummy)))\n            x = self.pool(F.relu(self.conv2(x)))\n            flat = x.view(1, -1).shape[1]\n        self.fc1 = nn.Linear(flat, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, num_classes)\n\n    def forward(self, x, return_features=False):\n        x = F.relu(self.conv1(x))\n        x = self.pool(x)\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        x = x.view(x.size(0), -1)\n        feat = F.relu(self.fc1(x))\n        feat = F.relu(self.fc2(feat))\n        logits = self.fc3(feat)\n        if return_features:\n            return feat, logits\n        return logits\n\n# Instantiate global model\nglobal_model = LeNetSmall(NUM_CLASSES).to(DEVICE)\nglobal_state = {k: v.cpu() for k, v in global_model.state_dict().items()}\n\n# Helper to create model from state dict\ndef model_from_state(state_dict):\n    m = LeNetSmall(NUM_CLASSES).to(DEVICE)\n    sd = {k: v.to(DEVICE) for k, v in state_dict.items()}\n    m.load_state_dict(sd)\n    return m\n\n# -----------------------------\n# Utility: ensure image tensors have shape (B,C,H,W)\n# -----------------------------\ndef ensure_batch_image_shape(x):\n    # x may be (C,H,W), (1,C,H,W), (B,C,H,W), or (B,1,C,H,W) etc.\n    # Return a tensor with shape (B,C,H,W)\n    if isinstance(x, torch.Tensor):\n        if x.dim() == 3:\n            return x.unsqueeze(0)\n        if x.dim() == 5 and x.size(1) == 1:\n            # shape (B,1,C,H,W) -> squeeze dim1\n            return x.squeeze(1)\n        if x.dim() == 5 and x.size(2) == 1:\n            # shape (B,C,1,H,W) unlikely, try to reshape\n            return x.squeeze(2)\n        return x\n    else:\n        return x\n\n# -----------------------------\n# FedAvg client update (single-step) with gradient capture\n# -----------------------------\ndef get_model_copy_for_client(state_dict):\n    return model_from_state(state_dict)\n\ndef client_update(client_id, global_state, return_grad_snapshot=False):\n    loader = client_loaders[client_id]\n    if loader is None:\n        return None, None, None, None\n    local_model = get_model_copy_for_client(global_state)\n    opt = torch.optim.SGD(local_model.parameters(), lr=CLIENT_LR, momentum=MOMENTUM)\n    local_model.train()\n    grad_snapshot = None\n    captured_label = None\n    captured_image = None\n    for epoch in range(LOCAL_EPOCHS):\n        for x, y, pth in loader:\n            # x: (B,C,H,W) normally; guard against extra dims\n            x = ensure_batch_image_shape(x)\n            # Defensive: if DataLoader produced shape (B,1,C,H,W) or similar, squeeze\n            if x.dim() == 5 and x.size(1) == 1:\n                x = x.squeeze(1)\n            x = x.to(DEVICE)\n            y = torch.tensor(y) if not isinstance(y, torch.Tensor) else y\n            y = y.to(DEVICE)\n            opt.zero_grad()\n            logits = local_model(x)\n            loss = F.cross_entropy(logits, y)\n            loss.backward()\n            # Capture per-parameter gradients BEFORE optimizer.step (this is what attacker sees)\n            if return_grad_snapshot and grad_snapshot is None:\n                # capture per-parameter gradients (CPU)\n                grad_snapshot = [p.grad.detach().cpu().clone() if p.grad is not None else None for p in local_model.parameters()]\n\n                # Ensure we capture a single example (first in the batch)\n                # y may be shape (B,) or (B,1); take first element and keep batch dim (1,)\n                if y.dim() == 0:\n                    captured_label = y.detach().cpu().clone().unsqueeze(0)   # scalar -> (1,)\n                else:\n                    captured_label = y.detach().cpu().clone().view(-1)[0:1]  # (1,)\n\n                # captured_image: ensure shape (1,C,H,W)\n                captured_image = x.detach().cpu().clone()[0:1]               # keep first example only\n\n                # Debug print (optional)\n                # print(f\"[DEBUG] client {client_id} captured shapes: x {x.shape}, y {y.shape}\")\n\n            opt.step()\n            # For strong leakage baseline, break after first batch\n            if LOCAL_EPOCHS == 1:\n                break\n    # compute delta = local_params - global_params (on CPU)\n    new_state = {k: v.cpu() for k, v in local_model.state_dict().items()}\n    delta = {k: new_state[k] - global_state[k] for k in new_state.keys()}\n    return delta, grad_snapshot, captured_label, captured_image\n\n# -----------------------------\n# Server aggregation (FedAvg)\n# -----------------------------\ndef server_aggregate(global_state, client_deltas, client_sizes):\n    total = sum(client_sizes) if sum(client_sizes) > 0 else 1\n    agg = {k: torch.zeros_like(v) for k, v in global_state.items()}\n    for delta, size in zip(client_deltas, client_sizes):\n        if delta is None:\n            continue\n        weight = size / total\n        for k in agg.keys():\n            agg[k] += delta[k] * weight\n    new_state = {k: global_state[k] + agg[k] for k in global_state.keys()}\n    return new_state\n\n# -----------------------------\n# Reconstruction utilities (IDLG with L-BFGS)\n# -----------------------------\ndef flatten_grads(grad_list):\n    vecs = []\n    for g in grad_list:\n        if g is None:\n            continue\n        # ensure on DEVICE\n        if not g.is_cuda:\n            g = g.to(DEVICE)\n        vecs.append(g.view(-1))\n    if len(vecs) == 0:\n        return torch.tensor([], device=DEVICE)\n    return torch.cat(vecs)\n\ndef tv_loss(img):\n    return torch.mean(torch.abs(img[:, :, :, 1:] - img[:, :, :, :-1])) + \\\n           torch.mean(torch.abs(img[:, :, 1:, :] - img[:, :, :-1, :]))\n\ndef assert_shapes_for_recon(x_init, observed_label, observed_grads):\n    # x_init should be (1,C,H,W)\n    if not isinstance(x_init, torch.Tensor):\n        raise RuntimeError(\"x_init must be a torch.Tensor\")\n    if x_init.dim() != 4 or x_init.size(0) != 1:\n        raise RuntimeError(f\"Reconstruction input must be (1,C,H,W), got {x_init.shape}\")\n    # observed_label should be (1,)\n    if observed_label is None:\n        raise RuntimeError(\"Observed label is None\")\n    if observed_label.dim() != 1 or observed_label.size(0) != 1:\n        raise RuntimeError(f\"Observed label must be shape (1,), got {observed_label.shape}\")\n    # grads: ensure flattened length > 0\n    flat = flatten_grads(observed_grads)\n    if flat.numel() == 0:\n        raise RuntimeError(\"Observed grads flattened to zero length; check grad capture\")\n\ndef reconstruct_idlg_lbfgs(model_state_for_attack, observed_grads_cpu, observed_label_cpu, iters=ATTACK_LBFGS_MAX_ITER):\n    # Ensure observed_label_cpu is shape (1,)\n    if observed_label_cpu is None:\n        raise ValueError(\"No observed label provided for reconstruction\")\n    if observed_label_cpu.dim() == 0:\n        observed_label_cpu = observed_label_cpu.unsqueeze(0)\n    else:\n        observed_label_cpu = observed_label_cpu.view(-1)[0:1]\n\n    # Build a model instance loaded with the pre-update state (on DEVICE)\n    model = model_from_state(model_state_for_attack)\n    model.eval()\n\n    # Move observed grads to DEVICE and flatten\n    obs = [g.to(DEVICE) if g is not None else None for g in observed_grads_cpu]\n    obs_flat = flatten_grads(obs).detach()\n\n    # Initialize x_hat in the same normalized space as training ([-1,1])\n    if ATTACK_INIT == \"random\":\n        x_hat = torch.randn(RECON_SHAPE, device=DEVICE, requires_grad=True)\n    else:\n        x_hat = torch.randn(RECON_SHAPE, device=DEVICE, requires_grad=True)\n\n    # Defensive shape assertion\n    try:\n        assert_shapes_for_recon(x_hat, observed_label_cpu, observed_grads_cpu)\n    except Exception as e:\n        raise RuntimeError(f\"Pre-reconstruction shape check failed: {e}\")\n\n    # Use LBFGS optimizer\n    optimizer = torch.optim.LBFGS([x_hat], max_iter=iters, line_search_fn='strong_wolfe' if ATTACK_LBFGS_LINESEARCH else None)\n\n    def closure():\n        optimizer.zero_grad()\n        x_in = ensure_batch_image_shape(x_hat)\n        logits = model(x_in)\n        loss_cls = F.cross_entropy(logits, observed_label_cpu.to(DEVICE))\n        grads_hat = torch.autograd.grad(loss_cls, list(model.parameters()), create_graph=True)\n        grads_hat_flat = flatten_grads(grads_hat)\n        if obs_flat.numel() == 0 or grads_hat_flat.numel() == 0:\n            loss = torch.tensor(0.0, device=DEVICE, requires_grad=True)\n            loss.backward()\n            return loss\n        loss_match = F.mse_loss(grads_hat_flat, obs_flat)\n        loss = ATTACK_GRAD_MATCH_WEIGHT * loss_match + ATTACK_TV_WEIGHT * tv_loss(x_hat)\n        loss.backward()\n        return loss\n\n    try:\n        optimizer.step(closure)\n    except Exception as e:\n        # LBFGS sometimes raises on line search; fallback to Adam for a while\n        print(\"LBFGS failed, falling back to Adam:\", e)\n        opt_adam = torch.optim.Adam([x_hat], lr=0.05)\n        for _ in range(500):\n            opt_adam.zero_grad()\n            x_in = ensure_batch_image_shape(x_hat)\n            logits = model(x_in)\n            loss_cls = F.cross_entropy(logits, observed_label_cpu.to(DEVICE))\n            grads_hat = torch.autograd.grad(loss_cls, list(model.parameters()), create_graph=True)\n            grads_hat_flat = flatten_grads(grads_hat)\n            loss_match = F.mse_loss(grads_hat_flat, obs_flat)\n            loss = ATTACK_GRAD_MATCH_WEIGHT * loss_match + ATTACK_TV_WEIGHT * tv_loss(x_hat)\n            loss.backward()\n            opt_adam.step()\n            with torch.no_grad():\n                x_hat.clamp_(-1, 1)\n\n    with torch.no_grad():\n        x_rec = x_hat.clamp_(-1, 1).detach().cpu()\n    return x_rec\n\n# -----------------------------\n# Evaluation metrics\n# -----------------------------\ndef denorm(img_tensor):\n    img = img_tensor.clone()\n    img = (img * 0.5) + 0.5\n    return img.clamp(0,1)\n\ndef compute_ssim(img1, img2):\n    a = img1.squeeze(0).permute(1,2,0).numpy()\n    b = img2.squeeze(0).permute(1,2,0).numpy()\n    s = 0.0\n    for ch in range(a.shape[2]):\n        s += ssim(a[:,:,ch], b[:,:,ch], data_range=1.0)\n    return s / a.shape[2]\n\ndef compute_cosine_similarity_feature(model_state, img1, img2):\n    model = model_from_state(model_state)\n    model.eval()\n    with torch.no_grad():\n        f1, _ = model(ensure_batch_image_shape(img1).to(DEVICE), return_features=True)\n        f2, _ = model(ensure_batch_image_shape(img2).to(DEVICE), return_features=True)\n    f1 = f1.cpu().numpy()\n    f2 = f2.cpu().numpy()\n    return float(cosine_similarity(f1, f2)[0,0])\n\ndef evaluate_accuracy(model_state, dataloader):\n    model = model_from_state(model_state)\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for x, y, _ in dataloader:\n            x = ensure_batch_image_shape(x).to(DEVICE)\n            y = y.to(DEVICE)\n            logits = model(x)\n            preds = logits.argmax(dim=1)\n            correct += (preds == y).sum().item()\n            total += y.size(0)\n    return correct / total if total > 0 else 0.0\n\n# -----------------------------\n# Training loop with attack during training\n# -----------------------------\nattack_logs = []\nglobal_state = {k: v.cpu() for k, v in global_model.state_dict().items()}\n\nfor rnd in range(ROUNDS):\n    available_clients = [c for c in range(NUM_CLIENTS) if client_loaders[c] is not None]\n    sampled = random.sample(available_clients, min(CLIENTS_PER_ROUND, len(available_clients)))\n    client_deltas = []\n    client_sizes = []\n\n    victim_client = sampled[0] if len(sampled) > 0 else None\n    captured_grad = None\n    captured_label = None\n    captured_image = None\n    model_state_sent_to_client = None\n\n    for c in sampled:\n        model_state_sent_to_client = {k: v.clone() for k, v in global_state.items()}\n        if c == victim_client:\n            delta, grad_snapshot, cap_label, cap_image = client_update(c, model_state_sent_to_client, return_grad_snapshot=True)\n            captured_grad = grad_snapshot\n            captured_label = cap_label\n            captured_image = cap_image\n        else:\n            delta, _, _, _ = client_update(c, model_state_sent_to_client, return_grad_snapshot=False)\n        client_deltas.append(delta)\n        size = len(client_loaders[c].dataset) if client_loaders[c] is not None else 0\n        client_sizes.append(size)\n\n    global_state = server_aggregate(global_state, client_deltas, client_sizes)\n\n    if rnd % PRINT_EVERY == 0 or rnd == ROUNDS - 1:\n        acc = evaluate_accuracy(global_state, test_loader)\n        print(f\"Round {rnd:03d}/{ROUNDS:03d} - Test accuracy: {acc:.4f} - sampled {len(sampled)} clients\")\n\n    if (rnd % ATTACK_EVERY_N_ROUNDS == 0) and (captured_grad is not None):\n        # Ensure captured_label and captured_image are present and shaped correctly\n        try:\n            if captured_label is None or captured_image is None:\n                raise RuntimeError(\"Captured label/image missing for attack\")\n            # Force shapes: label (1,), image (1,C,H,W)\n            if captured_label.dim() == 0:\n                captured_label = captured_label.unsqueeze(0)\n            else:\n                captured_label = captured_label.view(-1)[0:1]\n            if captured_image.dim() == 3:\n                captured_image = captured_image.unsqueeze(0)\n            elif captured_image.dim() == 5 and captured_image.size(1) == 1:\n                captured_image = captured_image.squeeze(1)\n            captured_image = captured_image[0:1]  # ensure single example\n        except Exception as e:\n            print(\"Captured data shape error, skipping attack this round:\", e)\n            continue\n\n        try:\n            reconstructed = reconstruct_idlg_lbfgs(model_state_sent_to_client, captured_grad, captured_label, iters=ATTACK_LBFGS_MAX_ITER)\n        except Exception as e:\n            print(\"Reconstruction failed:\", e)\n            reconstructed = None\n\n        if reconstructed is not None:\n            rec_den = denorm(reconstructed)\n            true_den = denorm(captured_image.cpu())\n\n            ssim_val = compute_ssim(rec_den, true_den)\n            cos_val = compute_cosine_similarity_feature(model_state_sent_to_client, rec_den.unsqueeze(0), true_den.unsqueeze(0))\n            success = float(cos_val >= ATTACK_COSINE_THRESHOLD)\n\n            def tensor_to_pil(img_tensor, fname):\n                arr = (img_tensor.squeeze(0).permute(1,2,0).numpy() * 255).astype(np.uint8)\n                Image.fromarray(arr).save(fname)\n\n            fname_rec = os.path.join(SAVE_RECON_DIR, f\"round{rnd:03d}_client{victim_client}_rec.png\")\n            fname_true = os.path.join(SAVE_RECON_DIR, f\"round{rnd:03d}_client{victim_client}_true.png\")\n            try:\n                tensor_to_pil(rec_den, fname_rec)\n                tensor_to_pil(true_den, fname_true)\n            except Exception:\n                np.save(fname_rec + \".npy\", rec_den.numpy())\n                np.save(fname_true + \".npy\", true_den.numpy())\n\n            log_entry = {\n                \"round\": int(rnd),\n                \"victim_client\": int(victim_client),\n                \"ssim\": float(ssim_val),\n                \"cosine\": float(cos_val),\n                \"success\": float(success),\n                \"recon_path\": fname_rec,\n                \"true_path\": fname_true,\n                \"label\": int(captured_label.item())\n            }\n            attack_logs.append(log_entry)\n            print(f\"[Attack] Round {rnd} client {victim_client}: SSIM={ssim_val:.4f}, Cos={cos_val:.4f}, Success={success}\")\n\n# -----------------------------\n# Final aggregated attack metrics and save logs\n# -----------------------------\ntotal_attacks = len(attack_logs)\nif total_attacks > 0:\n    avg_ssim = sum([e[\"ssim\"] for e in attack_logs]) / total_attacks\n    avg_cos = sum([e[\"cosine\"] for e in attack_logs]) / total_attacks\n    success_rate = sum([e[\"success\"] for e in attack_logs]) / total_attacks\nelse:\n    avg_ssim = avg_cos = success_rate = 0.0\n\nprint(\"=== Attack summary ===\")\nprint(f\"Attacks run: {total_attacks}\")\nprint(f\"Avg SSIM: {avg_ssim:.4f}\")\nprint(f\"Avg Cosine: {avg_cos:.4f}\")\nprint(f\"Success rate (cos>={ATTACK_COSINE_THRESHOLD}): {success_rate:.3f}\")\n\nwith open(os.path.join(SAVE_RECON_DIR, \"attack_logs.json\"), \"w\") as f:\n    json.dump(attack_logs, f, indent=2)\n\nprint(\"Reconstruction images and logs saved to:\", SAVE_RECON_DIR)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T19:18:29.344542Z","iopub.execute_input":"2025-12-24T19:18:29.345225Z","iopub.status.idle":"2025-12-24T19:19:50.992204Z","shell.execute_reply.started":"2025-12-24T19:18:29.345197Z","shell.execute_reply":"2025-12-24T19:19:50.991517Z"}},"outputs":[{"name":"stdout","text":"Found 9164 images across 1680 identities (>=2 images each).\nAssigned identities to 100 non-empty clients out of 100 total clients.\nRound 000/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 0 client 93: SSIM=0.0161, Cos=0.9953, Success=1.0\nRound 005/100 - Test accuracy: 0.0000 - sampled 10 clients\n[Attack] Round 5 client 9: SSIM=0.0117, Cos=0.9905, Success=1.0\nRound 010/100 - Test accuracy: 0.0000 - sampled 10 clients\n[Attack] Round 10 client 42: SSIM=0.0002, Cos=0.9952, Success=1.0\nRound 015/100 - Test accuracy: 0.0000 - sampled 10 clients\n[Attack] Round 15 client 28: SSIM=0.0078, Cos=0.9911, Success=1.0\nRound 020/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 20 client 59: SSIM=0.0091, Cos=0.9939, Success=1.0\nRound 025/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 25 client 42: SSIM=0.0083, Cos=0.9947, Success=1.0\nRound 030/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 30 client 30: SSIM=-0.0007, Cos=0.9921, Success=1.0\nRound 035/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 35 client 91: SSIM=0.0031, Cos=0.9873, Success=1.0\nRound 040/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 40 client 10: SSIM=0.0006, Cos=0.9915, Success=1.0\nRound 045/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 45 client 47: SSIM=0.0052, Cos=0.9802, Success=1.0\nRound 050/100 - Test accuracy: 0.0000 - sampled 10 clients\n[Attack] Round 50 client 20: SSIM=0.0013, Cos=0.9900, Success=1.0\nRound 055/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 55 client 16: SSIM=0.0026, Cos=0.9921, Success=1.0\nRound 060/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 60 client 79: SSIM=0.0051, Cos=0.9892, Success=1.0\nRound 065/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 65 client 78: SSIM=-0.0023, Cos=0.9823, Success=1.0\nRound 070/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 70 client 9: SSIM=0.0080, Cos=0.9830, Success=1.0\nRound 075/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 75 client 62: SSIM=0.0073, Cos=0.9880, Success=1.0\nRound 080/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 80 client 26: SSIM=0.0011, Cos=0.9838, Success=1.0\nRound 085/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 85 client 44: SSIM=0.0050, Cos=0.9825, Success=1.0\nRound 090/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 90 client 12: SSIM=0.0047, Cos=0.9868, Success=1.0\nRound 095/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 95 client 34: SSIM=-0.0035, Cos=0.9921, Success=1.0\nRound 099/100 - Test accuracy: 0.0006 - sampled 10 clients\n=== Attack summary ===\nAttacks run: 20\nAvg SSIM: 0.0045\nAvg Cosine: 0.9891\nSuccess rate (cos>=0.8): 1.000\nReconstruction images and logs saved to: ./reconstructions\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Diffrential Privacy - SGD in FL ( 50 Client)","metadata":{}},{"cell_type":"code","source":"# Single-cell runnable script: FedAvg (no protection) with ResNet-18 backbone on a local face dataset\n# and IDLG-style reconstruction attack during training using L-BFGS.\n#\n# This updated version fixes the RuntimeError:\n#   \"result type Float can't be cast to the desired output type Long\"\n# by ensuring model state tensors used for aggregation are float dtype\n# (BatchNorm's num_batches_tracked is Long and caused dtype mismatch).\n#\n# Requirements: torch, torchvision, numpy, pillow, scikit-image, tqdm, sklearn\n\nimport os\nimport random\nimport math\nimport json\nfrom collections import defaultdict\nfrom pathlib import Path\nfrom tqdm import tqdm\n\nimport numpy as np\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as T\nimport torchvision.models as models\nfrom skimage.metrics import structural_similarity as ssim\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# -----------------------------\n# Experiment hyperparameters\n# -----------------------------\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nSEED = 42\n\n# Federated learning variables\nNUM_CLIENTS = 50\nCLIENTS_PER_ROUND = 10\nROUNDS = 100\nLOCAL_EPOCHS = 1\nLOCAL_BATCH_SIZE = 1\nCLIENT_LR = 0.01\nMOMENTUM = 0.9\n\n# Model / data variables\nIMAGE_SIZE = 224\nINPUT_CHANNELS = 3\nNUM_CLASSES = None\n\n# Attack variables (IDLG with L-BFGS)\nATTACK_USE_LBFGS = True\nATTACK_LBFGS_MAX_ITER = 300\nATTACK_LBFGS_LINESEARCH = True\nATTACK_INIT = \"random\"\nATTACK_TV_WEIGHT = 1e-4\nATTACK_GRAD_MATCH_WEIGHT = 1.0\nATTACK_COSINE_THRESHOLD = 0.5\nATTACK_EVERY_N_ROUNDS = 1\n\nRECON_SHAPE = (1, INPUT_CHANNELS, IMAGE_SIZE, IMAGE_SIZE)\n\nPRINT_EVERY = 5\nSAVE_RECON_DIR = \"./reconstructions\"\nos.makedirs(SAVE_RECON_DIR, exist_ok=True)\n\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\nrandom.seed(SEED)\n\n# -----------------------------\n# Dataset utilities\n# -----------------------------\nDATA_ROOT = \"/kaggle/input/lfw-facial-recognition/Face Recognition\"\nFOLDERS = [\"Faces\"]\n\ntransform = T.Compose([\n    T.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    T.ToTensor(),\n    T.Normalize(mean=[0.5]*3, std=[0.5]*3)\n])\n\ndef gather_image_paths(root, folders):\n    paths = []\n    for f in folders:\n        folder = os.path.join(root, f)\n        if not os.path.isdir(folder):\n            continue\n        for fname in sorted(os.listdir(folder)):\n            if fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n                paths.append(os.path.join(folder, fname))\n    return sorted(paths)\n\nall_image_paths = gather_image_paths(DATA_ROOT, FOLDERS)\nif len(all_image_paths) == 0:\n    raise RuntimeError(f\"No images found in {FOLDERS} under {DATA_ROOT}. Check paths.\")\n\ndef identity_from_filename(path):\n    name = os.path.basename(path)\n    base = os.path.splitext(name)[0]\n    parts = base.split(\"_\")\n    if len(parts) >= 2:\n        return \"_\".join(parts[:-1])\n    return base\n\nid_to_paths = defaultdict(list)\nfor p in all_image_paths:\n    id_ = identity_from_filename(p)\n    id_to_paths[id_].append(p)\n\nvalid_id_to_paths = {k: v for k, v in id_to_paths.items() if len(v) >= 2}\nif len(valid_id_to_paths) == 0:\n    raise RuntimeError(\"No identities with >=2 images found. Check filename format or dataset.\")\n\nall_valid_paths = []\nall_valid_labels = []\nunique_ids = sorted(valid_id_to_paths.keys())\nlabel_map = {id_: idx for idx, id_ in enumerate(unique_ids)}\nfor id_, paths in valid_id_to_paths.items():\n    for p in paths:\n        all_valid_paths.append(p)\n        all_valid_labels.append(label_map[id_])\n\nNUM_CLASSES = len(unique_ids)\nprint(f\"Found {len(all_valid_paths)} images across {NUM_CLASSES} identities (>=2 images each).\")\n\n# -----------------------------\n# PyTorch Dataset and client partitioning\n# -----------------------------\nclass FaceImageDataset(Dataset):\n    def __init__(self, paths, labels, transform=None):\n        self.paths = paths\n        self.labels = labels\n        self.transform = transform\n    def __len__(self):\n        return len(self.paths)\n    def __getitem__(self, idx):\n        p = self.paths[idx]\n        img = Image.open(p).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n        label = int(self.labels[idx])\n        return img, label, p\n\nfull_dataset = FaceImageDataset(all_valid_paths, all_valid_labels, transform=transform)\n\nclient_id_to_indices = {c: [] for c in range(NUM_CLIENTS)}\nidentities = list(unique_ids)\nrandom.shuffle(identities)\nfor i, id_ in enumerate(identities):\n    client_id = i % NUM_CLIENTS\n    for p in valid_id_to_paths[id_]:\n        idx = all_valid_paths.index(p)\n        client_id_to_indices[client_id].append(idx)\n\nnum_nonempty = sum(1 for c in client_id_to_indices if len(client_id_to_indices[c]) > 0)\nprint(f\"Assigned identities to {num_nonempty} non-empty clients out of {NUM_CLIENTS} total clients.\")\n\nclient_loaders = {}\nfor c in range(NUM_CLIENTS):\n    inds = client_id_to_indices[c]\n    if len(inds) == 0:\n        client_loaders[c] = None\n        continue\n    sub_paths = [all_valid_paths[i] for i in inds]\n    sub_labels = [all_valid_labels[i] for i in inds]\n    ds = FaceImageDataset(sub_paths, sub_labels, transform=transform)\n    loader = DataLoader(ds, batch_size=LOCAL_BATCH_SIZE, shuffle=True)\n    client_loaders[c] = loader\n\ntest_paths = []\ntest_labels = []\nfor id_, paths in valid_id_to_paths.items():\n    p = paths[-1]\n    test_paths.append(p)\n    test_labels.append(label_map[id_])\ntest_ds = FaceImageDataset(test_paths, test_labels, transform=transform)\ntest_loader = DataLoader(test_ds, batch_size=32, shuffle=False)\n\n# -----------------------------\n# Model: ResNet-18 wrapper\n# -----------------------------\nclass ResNet18Wrapper(nn.Module):\n    def __init__(self, num_classes, pretrained=True):\n        super().__init__()\n        backbone = models.resnet18(pretrained=pretrained)\n        in_features = backbone.fc.in_features\n        backbone.fc = nn.Identity()\n        self.backbone = backbone\n        self.classifier = nn.Linear(in_features, num_classes)\n    def forward(self, x, return_features=False):\n        feats = self.backbone(x)\n        logits = self.classifier(feats)\n        if return_features:\n            return feats, logits\n        return logits\n\nglobal_model = ResNet18Wrapper(NUM_CLASSES, pretrained=True).to(DEVICE)\n\n# IMPORTANT: store global_state as float tensors to avoid dtype mismatch (BatchNorm num_batches_tracked is Long)\nglobal_state = {k: v.cpu().to(torch.float32) for k, v in global_model.state_dict().items()}\n\ndef model_from_state(state_dict):\n    m = ResNet18Wrapper(NUM_CLASSES, pretrained=False).to(DEVICE)\n    # state_dict may be float; ensure mapping to model dtype\n    sd = {}\n    for k, v in state_dict.items():\n        # cast to model device dtype\n        sd[k] = v.to(DEVICE)\n    m.load_state_dict(sd)\n    return m\n\n# -----------------------------\n# Utility: ensure image tensors have shape (B,C,H,W)\n# -----------------------------\ndef ensure_batch_image_shape(x):\n    if isinstance(x, torch.Tensor):\n        if x.dim() == 3:\n            return x.unsqueeze(0)\n        if x.dim() == 5 and x.size(1) == 1:\n            return x.squeeze(1)\n        if x.dim() == 5 and x.size(2) == 1:\n            return x.squeeze(2)\n        return x\n    else:\n        return x\n\n# -----------------------------\n# FedAvg client update (single-step) with gradient capture\n# -----------------------------\ndef get_model_copy_for_client(state_dict):\n    return model_from_state(state_dict)\n\ndef client_update(client_id, global_state, return_grad_snapshot=False):\n    loader = client_loaders[client_id]\n    if loader is None:\n        return None, None, None, None\n    local_model = get_model_copy_for_client(global_state)\n    opt = torch.optim.SGD(local_model.parameters(), lr=CLIENT_LR, momentum=MOMENTUM)\n    local_model.train()\n    grad_snapshot = None\n    captured_label = None\n    captured_image = None\n    for epoch in range(LOCAL_EPOCHS):\n        for x, y, pth in loader:\n            x = ensure_batch_image_shape(x)\n            if x.dim() == 5 and x.size(1) == 1:\n                x = x.squeeze(1)\n            x = x.to(DEVICE)\n            if not isinstance(y, torch.Tensor):\n                y = torch.tensor(y, dtype=torch.long)\n            else:\n                y = y.long()\n            y = y.to(DEVICE)\n            opt.zero_grad()\n            logits = local_model(x)\n            loss = F.cross_entropy(logits, y)\n            loss.backward()\n            if return_grad_snapshot and grad_snapshot is None:\n                grad_snapshot = [p.grad.detach().cpu().clone() if p.grad is not None else None for p in local_model.parameters()]\n                if y.dim() == 0:\n                    captured_label = y.detach().cpu().clone().unsqueeze(0).long()\n                else:\n                    captured_label = y.detach().cpu().clone().view(-1)[0:1].long()\n                captured_image = x.detach().cpu().clone()[0:1]\n            opt.step()\n            if LOCAL_EPOCHS == 1:\n                break\n    new_state = {k: v.cpu().to(torch.float32) for k, v in local_model.state_dict().items()}\n    delta = {k: new_state[k] - global_state[k] for k in new_state.keys()}\n    return delta, grad_snapshot, captured_label, captured_image\n\n# -----------------------------\n# Server aggregation (FedAvg) - ensure aggregation uses float dtype\n# -----------------------------\ndef server_aggregate(global_state, client_deltas, client_sizes):\n    total = sum(client_sizes) if sum(client_sizes) > 0 else 1\n    # create agg with float dtype explicitly\n    agg = {k: torch.zeros_like(global_state[k], dtype=torch.float32) for k in global_state.keys()}\n    for delta, size in zip(client_deltas, client_sizes):\n        if delta is None:\n            continue\n        weight = float(size) / float(total)\n        for k in agg.keys():\n            # ensure delta[k] is float\n            d = delta[k].to(torch.float32)\n            agg[k] = agg[k] + d * weight\n    # apply aggregation and keep float dtype\n    new_state = {k: (global_state[k].to(torch.float32) + agg[k].to(global_state[k].device)).cpu() for k in global_state.keys()}\n    return new_state\n\n# -----------------------------\n# Reconstruction utilities (IDLG with L-BFGS)\n# -----------------------------\ndef flatten_grads(grad_list):\n    vecs = []\n    for g in grad_list:\n        if g is None:\n            continue\n        if not g.is_cuda:\n            g = g.to(DEVICE)\n        vecs.append(g.view(-1))\n    if len(vecs) == 0:\n        return torch.tensor([], device=DEVICE)\n    return torch.cat(vecs)\n\ndef tv_loss(img):\n    return torch.mean(torch.abs(img[:, :, :, 1:] - img[:, :, :, :-1])) + \\\n           torch.mean(torch.abs(img[:, :, 1:, :] - img[:, :, :-1, :]))\n\ndef assert_shapes_for_recon(x_init, observed_label, observed_grads):\n    if not isinstance(x_init, torch.Tensor):\n        raise RuntimeError(\"x_init must be a torch.Tensor\")\n    if x_init.dim() != 4 or x_init.size(0) != 1:\n        raise RuntimeError(f\"Reconstruction input must be (1,C,H,W), got {x_init.shape}\")\n    if observed_label is None:\n        raise RuntimeError(\"Observed label is None\")\n    if observed_label.dim() != 1 or observed_label.size(0) != 1:\n        raise RuntimeError(f\"Observed label must be shape (1,), got {observed_label.shape}\")\n    flat = flatten_grads(observed_grads)\n    if flat.numel() == 0:\n        raise RuntimeError(\"Observed grads flattened to zero length; check grad capture\")\n\ndef reconstruct_idlg_lbfgs(model_state_for_attack, observed_grads_cpu, observed_label_cpu, iters=ATTACK_LBFGS_MAX_ITER):\n    if observed_label_cpu is None:\n        raise ValueError(\"No observed label provided for reconstruction\")\n    if observed_label_cpu.dim() == 0:\n        observed_label_cpu = observed_label_cpu.unsqueeze(0).long()\n    else:\n        observed_label_cpu = observed_label_cpu.view(-1)[0:1].long()\n\n    model = model_from_state(model_state_for_attack)\n    model.eval()\n\n    obs = [g.to(DEVICE) if g is not None else None for g in observed_grads_cpu]\n    obs_flat = flatten_grads(obs).detach()\n\n    if ATTACK_INIT == \"random\":\n        x_hat = torch.randn(RECON_SHAPE, device=DEVICE, requires_grad=True)\n    else:\n        x_hat = torch.randn(RECON_SHAPE, device=DEVICE, requires_grad=True)\n\n    try:\n        assert_shapes_for_recon(x_hat, observed_label_cpu, observed_grads_cpu)\n    except Exception as e:\n        raise RuntimeError(f\"Pre-reconstruction shape check failed: {e}\")\n\n    optimizer = torch.optim.LBFGS([x_hat], max_iter=iters, line_search_fn='strong_wolfe' if ATTACK_LBFGS_LINESEARCH else None)\n\n    def closure():\n        optimizer.zero_grad()\n        x_in = ensure_batch_image_shape(x_hat)\n        logits = model(x_in)\n        loss_cls = F.cross_entropy(logits, observed_label_cpu.to(DEVICE))\n        grads_hat = torch.autograd.grad(loss_cls, list(model.parameters()), create_graph=True)\n        grads_hat_flat = flatten_grads(grads_hat)\n        if obs_flat.numel() == 0 or grads_hat_flat.numel() == 0:\n            loss = torch.tensor(0.0, device=DEVICE, requires_grad=True)\n            loss.backward()\n            return loss\n        loss_match = F.mse_loss(grads_hat_flat, obs_flat)\n        loss = ATTACK_GRAD_MATCH_WEIGHT * loss_match + ATTACK_TV_WEIGHT * tv_loss(x_hat)\n        loss.backward()\n        return loss\n\n    try:\n        optimizer.step(closure)\n    except Exception as e:\n        print(\"LBFGS failed, falling back to Adam:\", e)\n        opt_adam = torch.optim.Adam([x_hat], lr=0.05)\n        for _ in range(500):\n            opt_adam.zero_grad()\n            x_in = ensure_batch_image_shape(x_hat)\n            logits = model(x_in)\n            loss_cls = F.cross_entropy(logits, observed_label_cpu.to(DEVICE))\n            grads_hat = torch.autograd.grad(loss_cls, list(model.parameters()), create_graph=True)\n            grads_hat_flat = flatten_grads(grads_hat)\n            loss_match = F.mse_loss(grads_hat_flat, obs_flat)\n            loss = ATTACK_GRAD_MATCH_WEIGHT * loss_match + ATTACK_TV_WEIGHT * tv_loss(x_hat)\n            loss.backward()\n            opt_adam.step()\n            with torch.no_grad():\n                x_hat.clamp_(-1, 1)\n\n    with torch.no_grad():\n        x_rec = x_hat.clamp_(-1, 1).detach().cpu()\n    return x_rec\n\n# -----------------------------\n# Evaluation metrics\n# -----------------------------\ndef denorm(img_tensor):\n    img = img_tensor.clone()\n    img = (img * 0.5) + 0.5\n    return img.clamp(0,1)\n\ndef compute_ssim(img1, img2):\n    a = img1.squeeze(0).permute(1,2,0).numpy()\n    b = img2.squeeze(0).permute(1,2,0).numpy()\n    s = 0.0\n    for ch in range(a.shape[2]):\n        s += ssim(a[:,:,ch], b[:,:,ch], data_range=1.0)\n    return s / a.shape[2]\n\ndef compute_cosine_similarity_feature(model_state, img1, img2):\n    model = model_from_state(model_state)\n    model.eval()\n    with torch.no_grad():\n        f1, _ = model(ensure_batch_image_shape(img1).to(DEVICE), return_features=True)\n        f2, _ = model(ensure_batch_image_shape(img2).to(DEVICE), return_features=True)\n    f1 = f1.cpu().numpy()\n    f2 = f2.cpu().numpy()\n    return float(cosine_similarity(f1, f2)[0,0])\n\ndef evaluate_accuracy(model_state, dataloader):\n    model = model_from_state(model_state)\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for x, y, _ in dataloader:\n            x = ensure_batch_image_shape(x).to(DEVICE)\n            if not isinstance(y, torch.Tensor):\n                y = torch.tensor(y, dtype=torch.long)\n            else:\n                y = y.long()\n            y = y.to(DEVICE)\n            logits = model(x)\n            preds = logits.argmax(dim=1)\n            correct += (preds == y).sum().item()\n            total += y.size(0)\n    return correct / total if total > 0 else 0.0\n\n# -----------------------------\n# Training loop with attack during training\n# -----------------------------\nattack_logs = []\nglobal_state = {k: v.cpu().to(torch.float32) for k, v in global_model.state_dict().items()}\n\nfor rnd in range(ROUNDS):\n    available_clients = [c for c in range(NUM_CLIENTS) if client_loaders[c] is not None]\n    sampled = random.sample(available_clients, min(CLIENTS_PER_ROUND, len(available_clients)))\n    client_deltas = []\n    client_sizes = []\n\n    victim_client = sampled[0] if len(sampled) > 0 else None\n    captured_grad = None\n    captured_label = None\n    captured_image = None\n    model_state_sent_to_client = None\n\n    for c in sampled:\n        model_state_sent_to_client = {k: v.clone() for k, v in global_state.items()}\n        if c == victim_client:\n            delta, grad_snapshot, cap_label, cap_image = client_update(c, model_state_sent_to_client, return_grad_snapshot=True)\n            captured_grad = grad_snapshot\n            captured_label = cap_label\n            captured_image = cap_image\n        else:\n            delta, _, _, _ = client_update(c, model_state_sent_to_client, return_grad_snapshot=False)\n        client_deltas.append(delta)\n        size = len(client_loaders[c].dataset) if client_loaders[c] is not None else 0\n        client_sizes.append(size)\n\n    global_state = server_aggregate(global_state, client_deltas, client_sizes)\n\n    if rnd % PRINT_EVERY == 0 or rnd == ROUNDS - 1:\n        acc = evaluate_accuracy(global_state, test_loader)\n        print(f\"Round {rnd:03d}/{ROUNDS:03d} - Test accuracy: {acc:.4f} - sampled {len(sampled)} clients\")\n\n    if (rnd % ATTACK_EVERY_N_ROUNDS == 0) and (captured_grad is not None):\n        try:\n            if captured_label is None or captured_image is None:\n                raise RuntimeError(\"Captured label/image missing for attack\")\n            if captured_label.dim() == 0:\n                captured_label = captured_label.unsqueeze(0).long()\n            else:\n                captured_label = captured_label.view(-1)[0:1].long()\n            if captured_image.dim() == 3:\n                captured_image = captured_image.unsqueeze(0)\n            elif captured_image.dim() == 5 and captured_image.size(1) == 1:\n                captured_image = captured_image.squeeze(1)\n            captured_image = captured_image[0:1]\n        except Exception as e:\n            print(\"Captured data shape error, skipping attack this round:\", e)\n            continue\n\n        try:\n            reconstructed = reconstruct_idlg_lbfgs(model_state_sent_to_client, captured_grad, captured_label, iters=ATTACK_LBFGS_MAX_ITER)\n        except Exception as e:\n            print(\"Reconstruction failed:\", e)\n            reconstructed = None\n\n        if reconstructed is not None:\n            rec_den = denorm(reconstructed)\n            true_den = denorm(captured_image.cpu())\n\n            ssim_val = compute_ssim(rec_den, true_den)\n            cos_val = compute_cosine_similarity_feature(model_state_sent_to_client, rec_den.unsqueeze(0), true_den.unsqueeze(0))\n            success = float(cos_val >= ATTACK_COSINE_THRESHOLD)\n\n            def tensor_to_pil(img_tensor, fname):\n                arr = (img_tensor.squeeze(0).permute(1,2,0).numpy() * 255).astype(np.uint8)\n                Image.fromarray(arr).save(fname)\n\n            fname_rec = os.path.join(SAVE_RECON_DIR, f\"round{rnd:03d}_client{victim_client}_rec.png\")\n            fname_true = os.path.join(SAVE_RECON_DIR, f\"round{rnd:03d}_client{victim_client}_true.png\")\n            try:\n                tensor_to_pil(rec_den, fname_rec)\n                tensor_to_pil(true_den, fname_true)\n            except Exception:\n                np.save(fname_rec + \".npy\", rec_den.numpy())\n                np.save(fname_true + \".npy\", true_den.numpy())\n\n            log_entry = {\n                \"round\": int(rnd),\n                \"victim_client\": int(victim_client),\n                \"ssim\": float(ssim_val),\n                \"cosine\": float(cos_val),\n                \"success\": float(success),\n                \"recon_path\": fname_rec,\n                \"true_path\": fname_true,\n                \"label\": int(captured_label.item())\n            }\n            attack_logs.append(log_entry)\n            print(f\"[Attack] Round {rnd} client {victim_client}: SSIM={ssim_val:.4f}, Cos={cos_val:.4f}, Success={success}\")\n\n# -----------------------------\n# Final aggregated attack metrics and save logs\n# -----------------------------\ntotal_attacks = len(attack_logs)\nif total_attacks > 0:\n    avg_ssim = sum([e[\"ssim\"] for e in attack_logs]) / total_attacks\n    avg_cos = sum([e[\"cosine\"] for e in attack_logs]) / total_attacks\n    success_rate = sum([e[\"success\"] for e in attack_logs]) / total_attacks\nelse:\n    avg_ssim = avg_cos = success_rate = 0.0\n\nprint(\"=== Attack summary ===\")\nprint(f\"Attacks run: {total_attacks}\")\nprint(f\"Avg SSIM: {avg_ssim:.4f}\")\nprint(f\"Avg Cosine: {avg_cos:.4f}\")\nprint(f\"Success rate (cos>={ATTACK_COSINE_THRESHOLD}): {success_rate:.3f}\")\n\nwith open(os.path.join(SAVE_RECON_DIR, \"attack_logs.json\"), \"w\") as f:\n    json.dump(attack_logs, f, indent=2)\n\nprint(\"Reconstruction images and logs saved to:\", SAVE_RECON_DIR)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T19:33:05.427401Z","iopub.execute_input":"2025-12-24T19:33:05.428085Z","iopub.status.idle":"2025-12-24T19:40:48.378042Z","shell.execute_reply.started":"2025-12-24T19:33:05.428055Z","shell.execute_reply":"2025-12-24T19:40:48.377381Z"}},"outputs":[{"name":"stdout","text":"Found 9164 images across 1680 identities (>=2 images each).\nAssigned identities to 50 non-empty clients out of 50 total clients.\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n100%|| 44.7M/44.7M [00:00<00:00, 226MB/s]\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 000/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 0 client 46: SSIM=0.0056, Cos=0.3156, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 1 client 9: SSIM=0.0031, Cos=0.3703, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 2 client 28: SSIM=0.0057, Cos=0.3647, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 3 client 28: SSIM=0.0057, Cos=0.2810, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 4 client 32: SSIM=0.0068, Cos=0.3263, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 005/100 - Test accuracy: 0.0000 - sampled 10 clients\n[Attack] Round 5 client 41: SSIM=0.0053, Cos=0.3426, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 6 client 28: SSIM=0.0052, Cos=0.3413, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 7 client 28: SSIM=0.0052, Cos=0.3948, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 8 client 45: SSIM=0.0049, Cos=0.3738, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 9 client 24: SSIM=0.0046, Cos=0.3476, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 010/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 10 client 21: SSIM=0.0045, Cos=0.3905, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 11 client 21: SSIM=0.0055, Cos=0.3863, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 12 client 38: SSIM=0.0035, Cos=0.3365, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 13 client 5: SSIM=0.0064, Cos=0.4566, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 14 client 13: SSIM=0.0050, Cos=0.4625, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 015/100 - Test accuracy: 0.0000 - sampled 10 clients\n[Attack] Round 15 client 32: SSIM=0.0044, Cos=0.4232, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 16 client 24: SSIM=0.0056, Cos=0.4031, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 17 client 23: SSIM=0.0032, Cos=0.4910, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 18 client 15: SSIM=0.0066, Cos=0.4440, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 19 client 49: SSIM=0.0053, Cos=0.3974, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 020/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 20 client 3: SSIM=0.0037, Cos=0.4575, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 21 client 48: SSIM=0.0059, Cos=0.4948, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 22 client 22: SSIM=0.0052, Cos=0.4654, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 23 client 23: SSIM=0.0048, Cos=0.4932, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 24 client 18: SSIM=0.0041, Cos=0.4818, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 025/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 25 client 1: SSIM=0.0040, Cos=0.4744, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 26 client 15: SSIM=0.0057, Cos=0.4708, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 27 client 7: SSIM=0.0053, Cos=0.5394, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 28 client 18: SSIM=0.0038, Cos=0.5371, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 29 client 33: SSIM=0.0048, Cos=0.5344, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 030/100 - Test accuracy: 0.0000 - sampled 10 clients\n[Attack] Round 30 client 30: SSIM=0.0045, Cos=0.5054, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 31 client 15: SSIM=0.0058, Cos=0.4601, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 32 client 34: SSIM=0.0044, Cos=0.5142, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 33 client 4: SSIM=0.0047, Cos=0.4393, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 34 client 19: SSIM=0.0065, Cos=0.5475, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 035/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 35 client 22: SSIM=0.0045, Cos=0.4900, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 36 client 24: SSIM=0.0053, Cos=0.4959, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 37 client 46: SSIM=0.0055, Cos=0.4803, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 38 client 5: SSIM=0.0033, Cos=0.5489, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 39 client 22: SSIM=0.0046, Cos=0.5410, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 040/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 40 client 4: SSIM=0.0016, Cos=0.5413, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 41 client 38: SSIM=0.0040, Cos=0.4679, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 42 client 24: SSIM=0.0045, Cos=0.4396, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 43 client 48: SSIM=0.0054, Cos=0.5479, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 44 client 15: SSIM=0.0054, Cos=0.5379, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 045/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 45 client 49: SSIM=0.0023, Cos=0.4901, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 46 client 8: SSIM=0.0043, Cos=0.4548, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 47 client 35: SSIM=0.0053, Cos=0.5102, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 48 client 14: SSIM=0.0043, Cos=0.5153, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 49 client 23: SSIM=0.0059, Cos=0.4770, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 050/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 50 client 33: SSIM=0.0060, Cos=0.4809, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 51 client 29: SSIM=0.0051, Cos=0.4768, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 52 client 27: SSIM=0.0058, Cos=0.5069, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 53 client 45: SSIM=0.0051, Cos=0.5061, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 54 client 17: SSIM=0.0038, Cos=0.4208, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 055/100 - Test accuracy: 0.0000 - sampled 10 clients\n[Attack] Round 55 client 37: SSIM=0.0048, Cos=0.5605, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 56 client 1: SSIM=0.0046, Cos=0.4573, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 57 client 39: SSIM=0.0036, Cos=0.4498, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 58 client 15: SSIM=0.0043, Cos=0.4823, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 59 client 30: SSIM=0.0064, Cos=0.6003, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 060/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 60 client 8: SSIM=0.0053, Cos=0.5296, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 61 client 17: SSIM=0.0042, Cos=0.5466, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 62 client 15: SSIM=0.0058, Cos=0.6035, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 63 client 31: SSIM=0.0049, Cos=0.5179, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 64 client 37: SSIM=0.0054, Cos=0.4794, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 065/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 65 client 34: SSIM=0.0035, Cos=0.5080, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 66 client 25: SSIM=0.0036, Cos=0.4842, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 67 client 32: SSIM=0.0032, Cos=0.5146, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 68 client 25: SSIM=0.0072, Cos=0.5199, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 69 client 32: SSIM=0.0055, Cos=0.4124, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 070/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 70 client 38: SSIM=0.0047, Cos=0.5250, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 71 client 37: SSIM=0.0047, Cos=0.5169, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 72 client 23: SSIM=0.0070, Cos=0.4670, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 73 client 30: SSIM=0.0052, Cos=0.5279, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 74 client 33: SSIM=0.0048, Cos=0.4852, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 075/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 75 client 44: SSIM=0.0058, Cos=0.4938, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 76 client 26: SSIM=0.0057, Cos=0.5046, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 77 client 42: SSIM=0.0048, Cos=0.5230, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 78 client 22: SSIM=0.0062, Cos=0.5143, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 79 client 15: SSIM=0.0055, Cos=0.4985, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 080/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 80 client 30: SSIM=0.0065, Cos=0.5643, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 81 client 25: SSIM=0.0066, Cos=0.5350, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 82 client 47: SSIM=0.0041, Cos=0.5252, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 83 client 39: SSIM=0.0055, Cos=0.5134, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 84 client 14: SSIM=0.0053, Cos=0.5399, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 085/100 - Test accuracy: 0.0000 - sampled 10 clients\n[Attack] Round 85 client 10: SSIM=0.0050, Cos=0.5398, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 86 client 41: SSIM=0.0055, Cos=0.5471, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 87 client 11: SSIM=0.0045, Cos=0.4899, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 88 client 38: SSIM=0.0061, Cos=0.5625, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 89 client 32: SSIM=0.0058, Cos=0.4614, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 090/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 90 client 45: SSIM=0.0059, Cos=0.5006, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 91 client 40: SSIM=0.0053, Cos=0.5083, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 92 client 8: SSIM=0.0052, Cos=0.5274, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 93 client 21: SSIM=0.0059, Cos=0.5380, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 94 client 3: SSIM=0.0045, Cos=0.5617, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 095/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 95 client 40: SSIM=0.0035, Cos=0.5691, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 96 client 47: SSIM=0.0050, Cos=0.5797, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 97 client 43: SSIM=0.0054, Cos=0.5255, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 98 client 7: SSIM=0.0037, Cos=0.4732, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 099/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 99 client 33: SSIM=0.0055, Cos=0.5008, Success=1.0\n=== Attack summary ===\nAttacks run: 100\nAvg SSIM: 0.0050\nAvg Cosine: 0.4828\nSuccess rate (cos>=0.5): 0.470\nReconstruction images and logs saved to: ./reconstructions\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Diffrential Privacy - SGD ( 10 client)","metadata":{}},{"cell_type":"code","source":"# Single-cell runnable script: FedAvg with ResNet-18 backbone + DP-SGD on clients,\n# and IDLG-style reconstruction attack during training using L-BFGS.\n#\n# Notes:\n# - This implements a simple, explicit DP-SGD on each client by computing per-sample\n#   gradients (via a loop over microbatches / samples), clipping each sample gradient\n#   to CLIP_NORM, averaging, adding Gaussian noise, and applying the noisy gradient\n#   update to the local model parameters.\n# - This is a straightforward, library-free DP implementation intended for clarity.\n#   For production-scale experiments, use Opacus or functorch for efficiency.\n#\n# Requirements: torch, torchvision, numpy, pillow, scikit-image, tqdm, sklearn\n# Adjust DATA_ROOT and FOLDERS to your dataset layout.\n\nimport os\nimport random\nimport math\nimport json\nfrom collections import defaultdict\nfrom pathlib import Path\nfrom tqdm import tqdm\n\nimport numpy as np\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as T\nimport torchvision.models as models\nfrom skimage.metrics import structural_similarity as ssim\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# -----------------------------\n# Experiment hyperparameters\n# -----------------------------\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nSEED = 42\n\n# Federated learning variables\nNUM_CLIENTS = 10\nCLIENTS_PER_ROUND = 10\nROUNDS = 100\nLOCAL_EPOCHS = 1\n\n# LOCAL_BATCH_SIZE is the client batch size used for computing per-sample grads.\n# For DP-SGD it's common to use batch sizes >= 8 to amortize noise; set as needed.\nLOCAL_BATCH_SIZE = 8\n\n# Client optimizer hyperparameters (used only for non-DP fallback updates)\nCLIENT_LR = 0.01\nMOMENTUM = 0.9\n\n# Model / data variables\nIMAGE_SIZE = 224\nINPUT_CHANNELS = 3\nNUM_CLASSES = None  # set after dataset scan\n\n# DP-SGD variables\nDP_ENABLED = True\nCLIP_NORM = 1.0            # C\nNOISE_MULTIPLIER = 1.0     # sigma\n# If you want to compute epsilon, use a privacy accountant (not included here)\n\n# Attack variables (IDLG with L-BFGS)\nATTACK_USE_LBFGS = True\nATTACK_LBFGS_MAX_ITER = 300\nATTACK_LBFGS_LINESEARCH = True\nATTACK_INIT = \"random\"\nATTACK_TV_WEIGHT = 1e-4\nATTACK_GRAD_MATCH_WEIGHT = 1.0\nATTACK_COSINE_THRESHOLD = 0.6\nATTACK_EVERY_N_ROUNDS = 1\n\nRECON_SHAPE = (1, INPUT_CHANNELS, IMAGE_SIZE, IMAGE_SIZE)\n\nPRINT_EVERY = 5\nSAVE_RECON_DIR = \"./reconstructions\"\nos.makedirs(SAVE_RECON_DIR, exist_ok=True)\n\n# Determinism\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\nrandom.seed(SEED)\n\n# -----------------------------\n# Dataset utilities\n# -----------------------------\n# Set your dataset path here\nDATA_ROOT = \"/kaggle/input/lfw-facial-recognition/Face Recognition\"\nFOLDERS = [\"Faces\"]  # or [\"detected faces\", \"Faces\"]\n\ntransform = T.Compose([\n    T.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    T.ToTensor(),\n    # Keep normalized to [-1,1] for reconstruction compatibility\n    T.Normalize(mean=[0.5]*3, std=[0.5]*3)\n])\n\ndef gather_image_paths(root, folders):\n    paths = []\n    for f in folders:\n        folder = os.path.join(root, f)\n        if not os.path.isdir(folder):\n            continue\n        for fname in sorted(os.listdir(folder)):\n            if fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n                paths.append(os.path.join(folder, fname))\n    return sorted(paths)\n\nall_image_paths = gather_image_paths(DATA_ROOT, FOLDERS)\nif len(all_image_paths) == 0:\n    raise RuntimeError(f\"No images found in {FOLDERS} under {DATA_ROOT}. Check paths.\")\n\ndef identity_from_filename(path):\n    name = os.path.basename(path)\n    base = os.path.splitext(name)[0]\n    parts = base.split(\"_\")\n    if len(parts) >= 2:\n        return \"_\".join(parts[:-1])\n    return base\n\nid_to_paths = defaultdict(list)\nfor p in all_image_paths:\n    id_ = identity_from_filename(p)\n    id_to_paths[id_].append(p)\n\nvalid_id_to_paths = {k: v for k, v in id_to_paths.items() if len(v) >= 2}\nif len(valid_id_to_paths) == 0:\n    raise RuntimeError(\"No identities with >=2 images found. Check filename format or dataset.\")\n\nall_valid_paths = []\nall_valid_labels = []\nunique_ids = sorted(valid_id_to_paths.keys())\nlabel_map = {id_: idx for idx, id_ in enumerate(unique_ids)}\nfor id_, paths in valid_id_to_paths.items():\n    for p in paths:\n        all_valid_paths.append(p)\n        all_valid_labels.append(label_map[id_])\n\nNUM_CLASSES = len(unique_ids)\nprint(f\"Found {len(all_valid_paths)} images across {NUM_CLASSES} identities (>=2 images each).\")\n\n# -----------------------------\n# PyTorch Dataset and client partitioning\n# -----------------------------\nclass FaceImageDataset(Dataset):\n    def __init__(self, paths, labels, transform=None):\n        self.paths = paths\n        self.labels = labels\n        self.transform = transform\n    def __len__(self):\n        return len(self.paths)\n    def __getitem__(self, idx):\n        p = self.paths[idx]\n        img = Image.open(p).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n        label = int(self.labels[idx])\n        return img, label, p\n\nfull_dataset = FaceImageDataset(all_valid_paths, all_valid_labels, transform=transform)\n\n# Partition identities across clients (non-IID)\nclient_id_to_indices = {c: [] for c in range(NUM_CLIENTS)}\nidentities = list(unique_ids)\nrandom.shuffle(identities)\nfor i, id_ in enumerate(identities):\n    client_id = i % NUM_CLIENTS\n    for p in valid_id_to_paths[id_]:\n        idx = all_valid_paths.index(p)\n        client_id_to_indices[client_id].append(idx)\n\nnum_nonempty = sum(1 for c in client_id_to_indices if len(client_id_to_indices[c]) > 0)\nprint(f\"Assigned identities to {num_nonempty} non-empty clients out of {NUM_CLIENTS} total clients.\")\n\nclient_loaders = {}\nfor c in range(NUM_CLIENTS):\n    inds = client_id_to_indices[c]\n    if len(inds) == 0:\n        client_loaders[c] = None\n        continue\n    sub_paths = [all_valid_paths[i] for i in inds]\n    sub_labels = [all_valid_labels[i] for i in inds]\n    ds = FaceImageDataset(sub_paths, sub_labels, transform=transform)\n    loader = DataLoader(ds, batch_size=LOCAL_BATCH_SIZE, shuffle=True)\n    client_loaders[c] = loader\n\n# Held-out test loader (one image per identity)\ntest_paths = []\ntest_labels = []\nfor id_, paths in valid_id_to_paths.items():\n    p = paths[-1]\n    test_paths.append(p)\n    test_labels.append(label_map[id_])\ntest_ds = FaceImageDataset(test_paths, test_labels, transform=transform)\ntest_loader = DataLoader(test_ds, batch_size=32, shuffle=False)\n\n# -----------------------------\n# Model: ResNet-18 wrapper\n# -----------------------------\nclass ResNet18Wrapper(nn.Module):\n    def __init__(self, num_classes, pretrained=True):\n        super().__init__()\n        backbone = models.resnet18(pretrained=pretrained)\n        in_features = backbone.fc.in_features\n        backbone.fc = nn.Identity()\n        self.backbone = backbone\n        self.classifier = nn.Linear(in_features, num_classes)\n    def forward(self, x, return_features=False):\n        feats = self.backbone(x)\n        logits = self.classifier(feats)\n        if return_features:\n            return feats, logits\n        return logits\n\nglobal_model = ResNet18Wrapper(NUM_CLASSES, pretrained=True).to(DEVICE)\n\n# Store global_state as float tensors to avoid dtype mismatch\nglobal_state = {k: v.cpu().to(torch.float32) for k, v in global_model.state_dict().items()}\n\ndef model_from_state(state_dict):\n    m = ResNet18Wrapper(NUM_CLASSES, pretrained=False).to(DEVICE)\n    sd = {k: v.to(DEVICE) for k, v in state_dict.items()}\n    m.load_state_dict(sd)\n    return m\n\n# -----------------------------\n# Utility: ensure image tensors have shape (B,C,H,W)\n# -----------------------------\ndef ensure_batch_image_shape(x):\n    if isinstance(x, torch.Tensor):\n        if x.dim() == 3:\n            return x.unsqueeze(0)\n        if x.dim() == 5 and x.size(1) == 1:\n            return x.squeeze(1)\n        if x.dim() == 5 and x.size(2) == 1:\n            return x.squeeze(2)\n        return x\n    else:\n        return x\n\n# -----------------------------\n# DP helpers: per-sample gradient computation, clipping, noise\n# -----------------------------\ndef compute_per_sample_grads(model, loss_fn, x_batch, y_batch):\n    \"\"\"\n    Compute per-sample gradients for a batch by looping over samples.\n    Returns a list (len = batch_size) of lists of gradients (one list per sample),\n    where each gradient list matches model.parameters() order.\n    \"\"\"\n    model.zero_grad()\n    per_sample_grads = []\n    batch_size = x_batch.size(0)\n    for i in range(batch_size):\n        xi = x_batch[i:i+1]\n        yi = y_batch[i:i+1]\n        logits = model(xi)\n        loss = loss_fn(logits, yi)\n        grads = torch.autograd.grad(loss, list(model.parameters()), retain_graph=False, create_graph=False)\n        # grads is a tuple of tensors (one per param)\n        per_sample_grads.append([g.detach().clone() if g is not None else None for g in grads])\n    return per_sample_grads\n\ndef clip_and_aggregate(per_sample_grads, clip_norm):\n    \"\"\"\n    per_sample_grads: list of samples, each is list of param grads\n    Returns aggregated (averaged) clipped gradients (list matching model.parameters()).\n    \"\"\"\n    batch_size = len(per_sample_grads)\n    # compute norms per sample\n    norms = []\n    for grads in per_sample_grads:\n        total_sq = 0.0\n        for g in grads:\n            if g is None:\n                continue\n            total_sq += (g.view(-1).float() ** 2).sum().item()\n        norms.append(math.sqrt(total_sq))\n    # clip and sum\n    summed = [torch.zeros_like(g) if g is not None else None for g in per_sample_grads[0]]\n    for i, grads in enumerate(per_sample_grads):\n        norm = norms[i]\n        clip_factor = 1.0\n        if norm > clip_norm and norm > 0:\n            clip_factor = clip_norm / (norm + 1e-12)\n        for j, g in enumerate(grads):\n            if g is None:\n                continue\n            g_clipped = g * clip_factor\n            if summed[j] is None:\n                summed[j] = g_clipped.clone()\n            else:\n                summed[j] += g_clipped\n    # average\n    avg = [ (s / float(batch_size)) if s is not None else None for s in summed ]\n    return avg\n\ndef add_noise_to_aggregated(aggregated_grads, clip_norm, noise_multiplier, batch_size):\n    \"\"\"\n    Add Gaussian noise to each parameter's aggregated gradient.\n    Noise std per parameter = noise_multiplier * clip_norm / batch_size\n    \"\"\"\n    noisy = []\n    std = noise_multiplier * clip_norm / float(max(1, batch_size))\n    for g in aggregated_grads:\n        if g is None:\n            noisy.append(None)\n            continue\n        noise = torch.normal(mean=0.0, std=std, size=g.shape, device=g.device, dtype=g.dtype)\n        noisy.append(g + noise)\n    return noisy\n\n# -----------------------------\n# FedAvg client update with DP-SGD\n# -----------------------------\ndef get_model_copy_for_client(state_dict):\n    return model_from_state(state_dict)\n\ndef client_update(client_id, global_state, return_grad_snapshot=False):\n    \"\"\"\n    Performs local training on client data.\n    If DP_ENABLED: compute per-sample grads, clip, add noise, and apply noisy update.\n    Returns: delta (state diff), optionally grad_snapshot (per-parameter grads for attack),\n             captured_label (1,), captured_image (1,C,H,W)\n    \"\"\"\n    loader = client_loaders[client_id]\n    if loader is None:\n        return None, None, None, None\n\n    local_model = get_model_copy_for_client(global_state)\n    local_model.train()\n\n    # We'll perform LOCAL_EPOCHS over the client's loader\n    grad_snapshot = None\n    captured_label = None\n    captured_image = None\n\n    loss_fn = nn.CrossEntropyLoss(reduction='mean')\n\n    for epoch in range(LOCAL_EPOCHS):\n        for x, y, pth in loader:\n            # ensure shapes\n            x = ensure_batch_image_shape(x)\n            if x.dim() == 5 and x.size(1) == 1:\n                x = x.squeeze(1)\n            # move to device\n            x = x.to(DEVICE)\n            # ensure labels are LongTensor\n            if not isinstance(y, torch.Tensor):\n                y = torch.tensor(y, dtype=torch.long)\n            else:\n                y = y.long()\n            y = y.to(DEVICE)\n\n            if DP_ENABLED:\n                # Compute per-sample gradients (on DEVICE)\n                per_sample_grads = compute_per_sample_grads(local_model, loss_fn, x, y)\n                # Clip and aggregate\n                aggregated = clip_and_aggregate(per_sample_grads, CLIP_NORM)\n                # Add Gaussian noise\n                noisy_agg = add_noise_to_aggregated(aggregated, CLIP_NORM, NOISE_MULTIPLIER, x.size(0))\n                # Apply noisy aggregated gradients as a gradient descent step:\n                # p.data = p.data - lr * noisy_grad\n                with torch.no_grad():\n                    for p, g_noisy in zip(local_model.parameters(), noisy_agg):\n                        if g_noisy is None:\n                            continue\n                        # ensure dtype/device\n                        g_noisy = g_noisy.to(p.device).to(p.dtype)\n                        p.data = p.data - CLIENT_LR * g_noisy\n                # For attack simulation: capture the (noisy or unclipped?) gradient snapshot.\n                # Attacker typically sees raw per-parameter gradients or parameter delta.\n                # We'll capture the aggregated (pre-noise) clipped gradient as the observed signal\n                if return_grad_snapshot and grad_snapshot is None:\n                    # store aggregated (clipped, pre-noise) grads on CPU\n                    grad_snapshot = [g.detach().cpu().clone() if g is not None else None for g in aggregated]\n                    # capture first sample label and image\n                    if y.dim() == 0:\n                        captured_label = y.detach().cpu().clone().unsqueeze(0).long()\n                    else:\n                        captured_label = y.detach().cpu().clone().view(-1)[0:1].long()\n                    captured_image = x.detach().cpu().clone()[0:1]\n            else:\n                # Non-DP baseline: standard SGD step (per-batch)\n                opt = torch.optim.SGD(local_model.parameters(), lr=CLIENT_LR, momentum=MOMENTUM)\n                opt.zero_grad()\n                logits = local_model(x)\n                loss = loss_fn(logits, y)\n                loss.backward()\n                if return_grad_snapshot and grad_snapshot is None:\n                    grad_snapshot = [p.grad.detach().cpu().clone() if p.grad is not None else None for p in local_model.parameters()]\n                    if y.dim() == 0:\n                        captured_label = y.detach().cpu().clone().unsqueeze(0).long()\n                    else:\n                        captured_label = y.detach().cpu().clone().view(-1)[0:1].long()\n                    captured_image = x.detach().cpu().clone()[0:1]\n                opt.step()\n\n            # break after first batch if LOCAL_EPOCHS==1 to simulate single-step leakage\n            if LOCAL_EPOCHS == 1:\n                break\n\n    # compute delta = local_params - global_params (on CPU, float)\n    new_state = {k: v.cpu().to(torch.float32) for k, v in local_model.state_dict().items()}\n    delta = {k: new_state[k] - global_state[k] for k in new_state.keys()}\n    return delta, grad_snapshot, captured_label, captured_image\n\n# -----------------------------\n# Server aggregation (FedAvg) - ensure float dtype\n# -----------------------------\ndef server_aggregate(global_state, client_deltas, client_sizes):\n    total = sum(client_sizes) if sum(client_sizes) > 0 else 1\n    agg = {k: torch.zeros_like(global_state[k], dtype=torch.float32) for k in global_state.keys()}\n    for delta, size in zip(client_deltas, client_sizes):\n        if delta is None:\n            continue\n        weight = float(size) / float(total)\n        for k in agg.keys():\n            d = delta[k].to(torch.float32)\n            agg[k] = agg[k] + d * weight\n    new_state = {k: (global_state[k].to(torch.float32) + agg[k]).cpu() for k in global_state.keys()}\n    return new_state\n\n# -----------------------------\n# Reconstruction utilities (IDLG with L-BFGS)\n# -----------------------------\ndef flatten_grads(grad_list):\n    vecs = []\n    for g in grad_list:\n        if g is None:\n            continue\n        if not g.is_cuda:\n            g = g.to(DEVICE)\n        vecs.append(g.view(-1))\n    if len(vecs) == 0:\n        return torch.tensor([], device=DEVICE)\n    return torch.cat(vecs)\n\ndef tv_loss(img):\n    return torch.mean(torch.abs(img[:, :, :, 1:] - img[:, :, :, :-1])) + \\\n           torch.mean(torch.abs(img[:, :, 1:, :] - img[:, :, :-1, :]))\n\ndef assert_shapes_for_recon(x_init, observed_label, observed_grads):\n    if not isinstance(x_init, torch.Tensor):\n        raise RuntimeError(\"x_init must be a torch.Tensor\")\n    if x_init.dim() != 4 or x_init.size(0) != 1:\n        raise RuntimeError(f\"Reconstruction input must be (1,C,H,W), got {x_init.shape}\")\n    if observed_label is None:\n        raise RuntimeError(\"Observed label is None\")\n    if observed_label.dim() != 1 or observed_label.size(0) != 1:\n        raise RuntimeError(f\"Observed label must be shape (1,), got {observed_label.shape}\")\n    flat = flatten_grads(observed_grads)\n    if flat.numel() == 0:\n        raise RuntimeError(\"Observed grads flattened to zero length; check grad capture\")\n\ndef reconstruct_idlg_lbfgs(model_state_for_attack, observed_grads_cpu, observed_label_cpu, iters=ATTACK_LBFGS_MAX_ITER):\n    if observed_label_cpu is None:\n        raise ValueError(\"No observed label provided for reconstruction\")\n    if observed_label_cpu.dim() == 0:\n        observed_label_cpu = observed_label_cpu.unsqueeze(0).long()\n    else:\n        observed_label_cpu = observed_label_cpu.view(-1)[0:1].long()\n\n    model = model_from_state(model_state_for_attack)\n    model.eval()\n\n    obs = [g.to(DEVICE) if g is not None else None for g in observed_grads_cpu]\n    obs_flat = flatten_grads(obs).detach()\n\n    if ATTACK_INIT == \"random\":\n        x_hat = torch.randn(RECON_SHAPE, device=DEVICE, requires_grad=True)\n    else:\n        x_hat = torch.randn(RECON_SHAPE, device=DEVICE, requires_grad=True)\n\n    try:\n        assert_shapes_for_recon(x_hat, observed_label_cpu, observed_grads_cpu)\n    except Exception as e:\n        raise RuntimeError(f\"Pre-reconstruction shape check failed: {e}\")\n\n    optimizer = torch.optim.LBFGS([x_hat], max_iter=iters, line_search_fn='strong_wolfe' if ATTACK_LBFGS_LINESEARCH else None)\n\n    def closure():\n        optimizer.zero_grad()\n        x_in = ensure_batch_image_shape(x_hat)\n        logits = model(x_in)\n        loss_cls = F.cross_entropy(logits, observed_label_cpu.to(DEVICE))\n        grads_hat = torch.autograd.grad(loss_cls, list(model.parameters()), create_graph=True)\n        grads_hat_flat = flatten_grads(grads_hat)\n        if obs_flat.numel() == 0 or grads_hat_flat.numel() == 0:\n            loss = torch.tensor(0.0, device=DEVICE, requires_grad=True)\n            loss.backward()\n            return loss\n        loss_match = F.mse_loss(grads_hat_flat, obs_flat)\n        loss = ATTACK_GRAD_MATCH_WEIGHT * loss_match + ATTACK_TV_WEIGHT * tv_loss(x_hat)\n        loss.backward()\n        return loss\n\n    try:\n        optimizer.step(closure)\n    except Exception as e:\n        print(\"LBFGS failed, falling back to Adam:\", e)\n        opt_adam = torch.optim.Adam([x_hat], lr=0.05)\n        for _ in range(500):\n            opt_adam.zero_grad()\n            x_in = ensure_batch_image_shape(x_hat)\n            logits = model(x_in)\n            loss_cls = F.cross_entropy(logits, observed_label_cpu.to(DEVICE))\n            grads_hat = torch.autograd.grad(loss_cls, list(model.parameters()), create_graph=True)\n            grads_hat_flat = flatten_grads(grads_hat)\n            loss_match = F.mse_loss(grads_hat_flat, obs_flat)\n            loss = ATTACK_GRAD_MATCH_WEIGHT * loss_match + ATTACK_TV_WEIGHT * tv_loss(x_hat)\n            loss.backward()\n            opt_adam.step()\n            with torch.no_grad():\n                x_hat.clamp_(-1, 1)\n\n    with torch.no_grad():\n        x_rec = x_hat.clamp_(-1, 1).detach().cpu()\n    return x_rec\n\n# -----------------------------\n# Evaluation metrics\n# -----------------------------\ndef denorm(img_tensor):\n    img = img_tensor.clone()\n    img = (img * 0.5) + 0.5\n    return img.clamp(0,1)\n\ndef compute_ssim(img1, img2):\n    a = img1.squeeze(0).permute(1,2,0).numpy()\n    b = img2.squeeze(0).permute(1,2,0).numpy()\n    s = 0.0\n    for ch in range(a.shape[2]):\n        s += ssim(a[:,:,ch], b[:,:,ch], data_range=1.0)\n    return s / a.shape[2]\n\ndef compute_cosine_similarity_feature(model_state, img1, img2):\n    model = model_from_state(model_state)\n    model.eval()\n    with torch.no_grad():\n        f1, _ = model(ensure_batch_image_shape(img1).to(DEVICE), return_features=True)\n        f2, _ = model(ensure_batch_image_shape(img2).to(DEVICE), return_features=True)\n    f1 = f1.cpu().numpy()\n    f2 = f2.cpu().numpy()\n    return float(cosine_similarity(f1, f2)[0,0])\n\ndef evaluate_accuracy(model_state, dataloader):\n    model = model_from_state(model_state)\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for x, y, _ in dataloader:\n            x = ensure_batch_image_shape(x).to(DEVICE)\n            if not isinstance(y, torch.Tensor):\n                y = torch.tensor(y, dtype=torch.long)\n            else:\n                y = y.long()\n            y = y.to(DEVICE)\n            logits = model(x)\n            preds = logits.argmax(dim=1)\n            correct += (preds == y).sum().item()\n            total += y.size(0)\n    return correct / total if total > 0 else 0.0\n\n# -----------------------------\n# Training loop with DP-SGD on clients and attack during training\n# -----------------------------\nattack_logs = []\nglobal_state = {k: v.cpu().to(torch.float32) for k, v in global_model.state_dict().items()}\n\nfor rnd in range(ROUNDS):\n    available_clients = [c for c in range(NUM_CLIENTS) if client_loaders[c] is not None]\n    sampled = random.sample(available_clients, min(CLIENTS_PER_ROUND, len(available_clients)))\n    client_deltas = []\n    client_sizes = []\n\n    victim_client = sampled[0] if len(sampled) > 0 else None\n    captured_grad = None\n    captured_label = None\n    captured_image = None\n    model_state_sent_to_client = None\n\n    for c in sampled:\n        model_state_sent_to_client = {k: v.clone() for k, v in global_state.items()}\n        if c == victim_client:\n            delta, grad_snapshot, cap_label, cap_image = client_update(c, model_state_sent_to_client, return_grad_snapshot=True)\n            captured_grad = grad_snapshot\n            captured_label = cap_label\n            captured_image = cap_image\n        else:\n            delta, _, _, _ = client_update(c, model_state_sent_to_client, return_grad_snapshot=False)\n        client_deltas.append(delta)\n        size = len(client_loaders[c].dataset) if client_loaders[c] is not None else 0\n        client_sizes.append(size)\n\n    # Aggregate and update global model\n    global_state = server_aggregate(global_state, client_deltas, client_sizes)\n\n    # Periodic evaluation\n    if rnd % PRINT_EVERY == 0 or rnd == ROUNDS - 1:\n        acc = evaluate_accuracy(global_state, test_loader)\n        print(f\"Round {rnd:03d}/{ROUNDS:03d} - Test accuracy: {acc:.4f} - sampled {len(sampled)} clients\")\n\n    # Attack during training (using pre-update model_state_sent_to_client)\n    if (rnd % ATTACK_EVERY_N_ROUNDS == 0) and (captured_grad is not None):\n        try:\n            if captured_label is None or captured_image is None:\n                raise RuntimeError(\"Captured label/image missing for attack\")\n            # Force shapes and dtype\n            if captured_label.dim() == 0:\n                captured_label = captured_label.unsqueeze(0).long()\n            else:\n                captured_label = captured_label.view(-1)[0:1].long()\n            if captured_image.dim() == 3:\n                captured_image = captured_image.unsqueeze(0)\n            elif captured_image.dim() == 5 and captured_image.size(1) == 1:\n                captured_image = captured_image.squeeze(1)\n            captured_image = captured_image[0:1]\n        except Exception as e:\n            print(\"Captured data shape error, skipping attack this round:\", e)\n            continue\n\n        try:\n            reconstructed = reconstruct_idlg_lbfgs(model_state_sent_to_client, captured_grad, captured_label, iters=ATTACK_LBFGS_MAX_ITER)\n        except Exception as e:\n            print(\"Reconstruction failed:\", e)\n            reconstructed = None\n\n        if reconstructed is not None:\n            rec_den = denorm(reconstructed)\n            true_den = denorm(captured_image.cpu())\n\n            ssim_val = compute_ssim(rec_den, true_den)\n            cos_val = compute_cosine_similarity_feature(model_state_sent_to_client, rec_den.unsqueeze(0), true_den.unsqueeze(0))\n            success = float(cos_val >= ATTACK_COSINE_THRESHOLD)\n\n            def tensor_to_pil(img_tensor, fname):\n                arr = (img_tensor.squeeze(0).permute(1,2,0).numpy() * 255).astype(np.uint8)\n                Image.fromarray(arr).save(fname)\n\n            fname_rec = os.path.join(SAVE_RECON_DIR, f\"round{rnd:03d}_client{victim_client}_rec.png\")\n            fname_true = os.path.join(SAVE_RECON_DIR, f\"round{rnd:03d}_client{victim_client}_true.png\")\n            try:\n                tensor_to_pil(rec_den, fname_rec)\n                tensor_to_pil(true_den, fname_true)\n            except Exception:\n                np.save(fname_rec + \".npy\", rec_den.numpy())\n                np.save(fname_true + \".npy\", true_den.numpy())\n\n            log_entry = {\n                \"round\": int(rnd),\n                \"victim_client\": int(victim_client),\n                \"ssim\": float(ssim_val),\n                \"cosine\": float(cos_val),\n                \"success\": float(success),\n                \"recon_path\": fname_rec,\n                \"true_path\": fname_true,\n                \"label\": int(captured_label.item())\n            }\n            attack_logs.append(log_entry)\n            print(f\"[Attack] Round {rnd} client {victim_client}: SSIM={ssim_val:.4f}, Cos={cos_val:.4f}, Success={success}\")\n\n# -----------------------------\n# Final aggregated attack metrics and save logs\n# -----------------------------\ntotal_attacks = len(attack_logs)\nif total_attacks > 0:\n    avg_ssim = sum([e[\"ssim\"] for e in attack_logs]) / total_attacks\n    avg_cos = sum([e[\"cosine\"] for e in attack_logs]) / total_attacks\n    success_rate = sum([e[\"success\"] for e in attack_logs]) / total_attacks\nelse:\n    avg_ssim = avg_cos = success_rate = 0.0\n\nprint(\"=== Attack summary ===\")\nprint(f\"Attacks run: {total_attacks}\")\nprint(f\"Avg SSIM: {avg_ssim:.4f}\")\nprint(f\"Avg Cosine: {avg_cos:.4f}\")\nprint(f\"Success rate (cos>={ATTACK_COSINE_THRESHOLD}): {success_rate:.3f}\")\n\nwith open(os.path.join(SAVE_RECON_DIR, \"attack_logs.json\"), \"w\") as f:\n    json.dump(attack_logs, f, indent=2)\n\nprint(\"Reconstruction images and logs saved to:\", SAVE_RECON_DIR)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T05:29:19.195239Z","iopub.execute_input":"2025-12-25T05:29:19.195755Z","iopub.status.idle":"2025-12-25T05:39:07.287255Z","shell.execute_reply.started":"2025-12-25T05:29:19.195726Z","shell.execute_reply":"2025-12-25T05:39:07.286571Z"}},"outputs":[{"name":"stdout","text":"Found 9164 images across 1680 identities (>=2 images each).\nAssigned identities to 10 non-empty clients out of 10 total clients.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 000/100 - Test accuracy: 0.0000 - sampled 10 clients\n[Attack] Round 0 client 2: SSIM=0.0031, Cos=0.2944, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 1 client 2: SSIM=0.0047, Cos=0.3689, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 2 client 2: SSIM=0.0054, Cos=0.4416, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 3 client 8: SSIM=0.0049, Cos=0.5508, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 4 client 1: SSIM=0.0052, Cos=0.4950, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 005/100 - Test accuracy: 0.0000 - sampled 10 clients\n[Attack] Round 5 client 9: SSIM=0.0055, Cos=0.5267, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 6 client 0: SSIM=0.0029, Cos=0.4846, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 7 client 6: SSIM=0.0061, Cos=0.5028, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 8 client 8: SSIM=0.0046, Cos=0.5319, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 9 client 5: SSIM=0.0035, Cos=0.4898, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 010/100 - Test accuracy: 0.0000 - sampled 10 clients\n[Attack] Round 10 client 2: SSIM=0.0061, Cos=0.5258, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 11 client 2: SSIM=0.0074, Cos=0.4399, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 12 client 4: SSIM=0.0052, Cos=0.5089, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 13 client 2: SSIM=0.0046, Cos=0.5245, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 14 client 9: SSIM=0.0051, Cos=0.5786, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 015/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 15 client 9: SSIM=0.0046, Cos=0.6031, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 16 client 4: SSIM=0.0051, Cos=0.5244, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 17 client 1: SSIM=0.0061, Cos=0.5913, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 18 client 5: SSIM=0.0036, Cos=0.5184, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 19 client 5: SSIM=0.0045, Cos=0.5120, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 020/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 20 client 7: SSIM=0.0057, Cos=0.5622, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 21 client 2: SSIM=0.0061, Cos=0.5138, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 22 client 6: SSIM=0.0039, Cos=0.5253, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 23 client 4: SSIM=0.0060, Cos=0.4875, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 24 client 1: SSIM=0.0056, Cos=0.5296, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 025/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 25 client 5: SSIM=0.0052, Cos=0.6271, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 26 client 8: SSIM=0.0043, Cos=0.4901, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 27 client 1: SSIM=0.0052, Cos=0.5376, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 28 client 8: SSIM=0.0058, Cos=0.4896, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 29 client 4: SSIM=0.0041, Cos=0.5177, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 030/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 30 client 7: SSIM=0.0007, Cos=0.5762, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 31 client 5: SSIM=0.0053, Cos=0.4850, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 32 client 7: SSIM=0.0057, Cos=0.5638, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 33 client 6: SSIM=0.0048, Cos=0.5375, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 34 client 3: SSIM=0.0042, Cos=0.5656, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 035/100 - Test accuracy: 0.0000 - sampled 10 clients\n[Attack] Round 35 client 5: SSIM=0.0037, Cos=0.5382, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 36 client 3: SSIM=0.0054, Cos=0.5534, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 37 client 4: SSIM=0.0076, Cos=0.5228, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 38 client 7: SSIM=0.0057, Cos=0.5949, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 39 client 4: SSIM=0.0051, Cos=0.5113, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 040/100 - Test accuracy: 0.0000 - sampled 10 clients\n[Attack] Round 40 client 3: SSIM=0.0047, Cos=0.5481, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 41 client 1: SSIM=0.0042, Cos=0.5849, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 42 client 5: SSIM=0.0043, Cos=0.5480, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 43 client 6: SSIM=0.0056, Cos=0.6056, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 44 client 5: SSIM=0.0043, Cos=0.6503, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 045/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 45 client 4: SSIM=0.0048, Cos=0.5748, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 46 client 0: SSIM=0.0042, Cos=0.4983, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 47 client 7: SSIM=0.0026, Cos=0.5854, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 48 client 7: SSIM=0.0033, Cos=0.5467, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 49 client 9: SSIM=0.0033, Cos=0.5166, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 050/100 - Test accuracy: 0.0000 - sampled 10 clients\n[Attack] Round 50 client 8: SSIM=0.0047, Cos=0.4716, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 51 client 2: SSIM=0.0058, Cos=0.5466, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 52 client 9: SSIM=0.0073, Cos=0.5684, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 53 client 0: SSIM=0.0068, Cos=0.5401, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 54 client 0: SSIM=0.0047, Cos=0.5352, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 055/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 55 client 6: SSIM=0.0041, Cos=0.4894, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 56 client 9: SSIM=0.0058, Cos=0.5364, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 57 client 9: SSIM=0.0055, Cos=0.5642, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 58 client 3: SSIM=0.0050, Cos=0.5318, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 59 client 8: SSIM=0.0035, Cos=0.5439, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 060/100 - Test accuracy: 0.0000 - sampled 10 clients\n[Attack] Round 60 client 6: SSIM=0.0051, Cos=0.5325, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 61 client 0: SSIM=0.0057, Cos=0.5604, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 62 client 4: SSIM=0.0026, Cos=0.5916, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 63 client 9: SSIM=0.0044, Cos=0.5876, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 64 client 6: SSIM=0.0036, Cos=0.5325, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 065/100 - Test accuracy: 0.0000 - sampled 10 clients\n[Attack] Round 65 client 7: SSIM=0.0061, Cos=0.5788, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 66 client 9: SSIM=0.0041, Cos=0.5807, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 67 client 3: SSIM=0.0059, Cos=0.5360, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 68 client 6: SSIM=0.0051, Cos=0.5571, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 69 client 7: SSIM=0.0059, Cos=0.5426, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 070/100 - Test accuracy: 0.0000 - sampled 10 clients\n[Attack] Round 70 client 3: SSIM=0.0044, Cos=0.5063, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 71 client 1: SSIM=0.0044, Cos=0.4990, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 72 client 5: SSIM=0.0065, Cos=0.5731, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 73 client 6: SSIM=0.0045, Cos=0.5468, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 74 client 0: SSIM=0.0035, Cos=0.5231, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 075/100 - Test accuracy: 0.0000 - sampled 10 clients\n[Attack] Round 75 client 3: SSIM=0.0069, Cos=0.6310, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 76 client 5: SSIM=0.0071, Cos=0.5947, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 77 client 6: SSIM=0.0037, Cos=0.6143, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 78 client 3: SSIM=0.0065, Cos=0.5223, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 79 client 0: SSIM=0.0057, Cos=0.5074, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 080/100 - Test accuracy: 0.0000 - sampled 10 clients\n[Attack] Round 80 client 5: SSIM=0.0028, Cos=0.5148, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 81 client 8: SSIM=0.0037, Cos=0.5862, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 82 client 1: SSIM=0.0036, Cos=0.5231, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 83 client 5: SSIM=0.0032, Cos=0.5277, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 84 client 7: SSIM=0.0056, Cos=0.6189, Success=1.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 085/100 - Test accuracy: 0.0000 - sampled 10 clients\n[Attack] Round 85 client 6: SSIM=0.0041, Cos=0.5095, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 86 client 1: SSIM=0.0045, Cos=0.5971, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 87 client 6: SSIM=0.0059, Cos=0.5666, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 88 client 1: SSIM=0.0046, Cos=0.5790, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 89 client 8: SSIM=0.0052, Cos=0.5266, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 090/100 - Test accuracy: 0.0006 - sampled 10 clients\n[Attack] Round 90 client 3: SSIM=0.0059, Cos=0.5182, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 91 client 1: SSIM=0.0057, Cos=0.5320, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 92 client 7: SSIM=0.0055, Cos=0.4583, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 93 client 3: SSIM=0.0034, Cos=0.5852, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 94 client 8: SSIM=0.0046, Cos=0.5443, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 095/100 - Test accuracy: 0.0000 - sampled 10 clients\n[Attack] Round 95 client 6: SSIM=0.0045, Cos=0.5368, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 96 client 2: SSIM=0.0043, Cos=0.5288, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 97 client 3: SSIM=0.0041, Cos=0.5438, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"[Attack] Round 98 client 9: SSIM=0.0052, Cos=0.5243, Success=0.0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Round 099/100 - Test accuracy: 0.0000 - sampled 10 clients\n[Attack] Round 99 client 4: SSIM=0.0063, Cos=0.5614, Success=0.0\n=== Attack summary ===\nAttacks run: 100\nAvg SSIM: 0.0049\nAvg Cosine: 0.5373\nSuccess rate (cos>=0.6): 0.070\nReconstruction images and logs saved to: ./reconstructions\n","output_type":"stream"}],"execution_count":2}]}